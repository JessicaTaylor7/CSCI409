,Document Title,PublicationAvenue,Publication Year,Abstract,Article Citation Count
1,The implementation of adaptive requirements engineering process based on case-based reasoning,2017 5th International Conference on Information and Communication Technology (ICoIC7),2017,"One major reason of failure in IT projects is a problem in requirements given by stakeholders, such as incomplete, inconsistent, and incorrect requirements. Requirements Engineering (RE) is a phase in software development life cycle that plays a critical role in determining software requirements from user requirements. Therefore RE could be very influential in determining software quality. Factors that influence the process of RE are organization culture, application domain, and the characteristics of the project. Characteristics and attributes of the IT project should determine the choice of RE processes and techniques. In this paper we present the adaptive process of RE which is based on IT projects characteristics and attributes. We believe conducting RE process based on the right IT projects characteristics and attributes will give more benefits in terms of effectiveness and efficiency. Case-based reasoning approach was adopted for the adaptive process of RE in this study. The IT project parameters that used are project size, complexity, requirements volatility, project category, degree of safety criticality, time and cost constraints. Output of adaptive process of RE is a RE process model recommendation. To evaluate the RE adaptive process, prototype software were developed and used three IT projects as case studies. Results from the experiment showed that the RE process model recommendation helps developer in conducting RE process and the output recommendation satisfied its users.",1
2,Model-based abductive reasoning in automated software testing,Logic Journal of the IGPL,2013,"Automated Software Testing (AST) using Model Checking is in this article epistemologically analysed in order to argue in favour of a model-based reasoning paradigm in computer science. Preliminarily, it is shown how both deductive and inductive reasoning are insufficient to determine whether a given piece of software is correct with respect to specified behavioural properties. Models algorithmically checked in Model Checking to select executions to be observed in Software Testing are acknowledged as analogical models which establish isomorphic relations with the target system's data set. Analogical models developed in AST are presented as abductive models providing hypothetical explanations to observed executions. The model assumption—algorithmic check—software testing process is understood as the abduction—deduction—induction process defining the selective abduction and turned to isolate a set of model-based hypotheses concerning the target system behaviours. A manipulative abduction process is finally recognized in the practice of adapting, abstracting and refining models that do not provide successful predictions.",0
3,An empirical investigation of multiple viewpoint reasoning in requirements engineering,Proceedings IEEE International Symposium on Requirements Engineering (Cat. No.PR00188),1999,"Multiple viewpoints are often used in requirements engineering to facilitate traceability to stakeholders, to structure the requirements process, and to provide richer modelling by incorporating multiple conflicting descriptions. In the latter case, the need to reason with inconsistent models introduces considerable extra complexity. We describe an empirical study of the utility of multiple world reasoning (using abduction) for domain modelling. In the study we used a range of different models (ranging from correct to very incorrect), different fanouts, different amounts of data available from the domain, and different modelling primitives for representing time. In the experiments there was no significant change in the expressive power of models that incorporate multiple conflicting viewpoints. Whilst this does not negate the advantages of viewpoints during requirements elicitation it does suggest some limits to the utility of viewpoints during requirements modelling.",18
4,Software design support using case-based reasoning,Proceedings of International Conference on Expert Systems for Development,1994,"This paper proposes a software design support method using case-based reasoning. The need for raising productivity in software development has long been felt, and a variety of design methods have been proposed in response to this need. These, however, deal mostly with rough procedures, and there is a need for detailed procedures that designers can follow when performing actual design work. One technique for obtaining a detailed procedure would be to refer to actual design cases from the past. The problem here, though, is that such information has not normally been collected and stored because of the additional burden placed on software designers. The authors have thus investigated a way to record design information during design work without placing a burden on the designer, and have developed a system to support design work by effectively reusing past design cases. In this system, past design cases are recorded, and through the use of case-based reasoning techniques, the design procedure and design results are presented to the designer as reusable candidates.<>",1
5,Reasoning-Based Software Testing,2023 IEEE/ACM 45th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER),2023,"With software systems becoming increasingly pervasive and autonomous, our ability to test for their quality is severely challenged. Many systems are called to operate in uncertain and highly-changing environment, not rarely required to make intelligent decisions by themselves. This easily results in an intractable state space to explore at testing time. The state-of-the-art techniques try to keep the pace, e.g., by augmenting the tester’s intuition with some form of (explicit or implicit) learning from observations to search this space efficiently. For instance, they exploit historical data to drive the search (e.g., ML-driven testing) or the tests execution data itself (e.g., adaptive or search-based testing). Despite the indubitable advances, the need for smartening the search in such a huge space keeps to be pressing.We introduce Reasoning-Based Software Testing (RBST), a new way of thinking at the testing problem as a causal reasoning task. Compared to mere intuition-based or state-of-the-art learning-based strategies, we claim that causal reasoning more naturally emulates the process that a human would do to ""smartly"" search the space. RBST aims to mimic and amplify, with the power of computation, this ability. The conceptual leap can pave the ground to a new trend of techniques, which can be variously instantiated from the proposed framework, by exploiting the numerous tools for causal discovery and inference. Preliminary results reported in this paper are promising.",0
6,The application of fuzzy enhanced case-based reasoning for identifying fault-prone modules,Proceedings Third IEEE International High-Assurance Systems Engineering Symposium (Cat. No.98EX231),1998,"As highly reliable software is becoming an essential ingredient in many systems, the process of assuring reliability can be a time-consuming, costly process. One way to improve the efficiency of the quality assurance process is to target reliability enhancement activities to those modules that are likely to have the most problems. Within the field of software engineering, much research has been performed to allow developers to identify fault-prone modules within a project. Software quality classification models can select the modules that are the most likely to contain faults so that reliability enhancement activities can be performed to lower the occurrences of software faults and errors. This paper introduces fuzzy logic combined with case-based reasoning (CBR) to determine fault-prone modules given a set of software metrics. Combining these two techniques promises more robust, flexible and accurate models. In this paper, we describe this approach, apply it in a real-world case study and discuss the results. The case study applied this approach to software quality modeling using data from a military command, control and communications (C/sup 3/) system. The fuzzy CBR model had an overall classification accuracy of more than 85%. This paper also discusses possible improvements and enhancements to the initial model that can be explored in the future.",5
7,Coordinated software development: A framework for reasoning about trace links in software systems,2009 International Conference on Intelligent Engineering Systems,2009,"Traceability is an important factor in the success of software projects. However, achieving software traceability has proven to be costly. In this paper, we provide a root cause analysis of the cost problems in conventional traceability approaches. Based on this analysis, we propose technical criteria for a more affordable solution to the traceability problem. We then present a new framework for achieving traceability that satisfies the proposed criteria. Our approach uses coordinated software development as an enabling mechanism to support reasoning about trace links in software systems. Early evaluation of our approach shows encouraging results.",2
8,Requirements refinements and analysis with case-based reasoning techniques to reuse the requirements,2015 International Conference on Electrical Engineering and Informatics (ICEEI),2015,"This paper proposes an approach in Goal-Oriented Requirements refinement and analysis that adapt Case-Based Reasoning techniques. This approach is expected to help emphasizing the reuse of the high quality requirements that have been applied on previous system development process. The Attributed Goal-Oriented Requirements Analysis (AGORA) is simplified to analyze requirements proposed by Goal Tree Model Case-Based. An information system project for a transportation company has been used as a case study to demonstrate this approach. The case study helped demonstrated that the generated requirements using our approach are able to accomplish the company needs, rather than user requirements that are caused by the user's interest in requirements engineering process.",2
9,Software Reuse and Reusability Based on Requirements: Feature Modelling vs. Case-Based Reasoning,2019 IEEE 27th International Requirements Engineering Conference (RE),2019,"Software reuse and reusability range from operational, ad-hoc and short-term to strategic, planned and long-term. Often the focus of attention is just on code or low-level design. This tutorial presents and compares two different requirements-led approaches. The first approach deals with requirements reuse and reusability using feature modelling. The second approach deals with requirements reuse and reusability in the context of case-based reasoning. Both approaches have different key properties and trade-offs between the costs of making software artefacts reusable and the benefits of reusing them. To aid large-scale development, we have proposed a Feature-Similarity Model, which draws on both approaches to facilitate discovering requirements relationships using similarity metrics. A Feature-Similarity Model also helps with the evolution of a product line, since new requirements can be introduced first into a case base and then gradually included into a product line representation.",0
10,Predicting software stability using case-based reasoning,"Proceedings 17th IEEE International Conference on Automated Software Engineering,",2002,"Predicting stability in object-oriented (OO) software, i.e., the ease with which a software item can evolve while preserving its design, is a key feature for software maintenance. We present a novel approach which relies on the case-based reasoning (CBR) paradigm. Thus, to predict the chances of an OO software item breaking downward compatibility, our method uses knowledge of past evolution extracted from different software versions. A comparison of our similarity-based approach to a classical inductive method such as decision trees, is presented which includes various tests on large datasets from existing software.",21
11,Conceptual model-based reasoning for knowledge-based software project management,[1988] Proceedings of the Twenty-First Annual Hawaii International Conference on System Sciences. Volume III: Decision Support and Knowledge Based Systems Track,1988,"The authors discusses the Software Project Manager (SPM), which has been prototyped in Interference Corporation's Automated Reasoning Tool (ART) on Symbolics artificial-intelligence workstations. They present an overview of the management model underlying SPM and define the essential concepts and relationships needed to model the project-management domain. They describe the knowledge representation strategy used to implement this conceptual model. They illustrate the power of using conceptual model-based reasoning in building intelligent decision-support systems for the project management domain.<>",5
12,Towards modelling and reasoning support for early-phase requirements engineering,Proceedings of ISRE '97: 3rd IEEE International Symposium on Requirements Engineering,1997,"Requirements are usually understood as stating what a system is supposed to do, as apposed to how it should do it. However, understanding the organizational context and rationales (the ""Whys"") that lead up to systems requirements can be just as important for the ongoing success of the system. Requirements modelling techniques can be used to help deal with the knowledge and reasoning needed in this earlier phase of requirements engineering. However most existing requirements techniques are intended more for the later phase of requirements engineering, which focuses on completeness, consistency, and automated verification of requirements. In contrast, the early phase aims to model and analyze stakeholder interests and how they might be addressed, or compromised, by various system-and-environment alternatives. This paper argues, therefore, that a different kind of modelling and reasoning support is needed for the early phase. An outline of the i* framework is given as an example of a step in this direction. Meeting scheduling is used as a domain example.",623
13,Modeling and reasoning for confidentiality requirements in software development,13th Annual IEEE International Symposium and Workshop on Engineering of Computer-Based Systems (ECBS'06),2006,"Requirements engineering has attained an important role in software development over the last few years as developers and other stakeholders have realized the importance of adequate requirement analysis and design in software development processes. However, the specification and analysis of functional requirements is better established compared to non-functional requirements. This could be attributed to the fact that nonfunctional requirements, such as reliability, accuracy, performance, usability and security are often subjective. Security requirements are often incorporated in an ad hoc manner or considered at post-requirement phase. It is believed that addressing these requirements during the early phase of system development improves the quality of developed applications. Confidentiality is an aspect of a system's security requirements aimed at preventing unauthorized use of personal or corporate data. Concerns from the different stakeholders which can be diverging, have to be addressed, in realizing confidentiality requirements. These concerns are also usually influenced by proposed system functions. This research is aimed at precisely defining confidentiality requirements and applying this for modelling and reasoning in confidentiality requirements engineering",1
14,Preliminary Study of Reasoning Existing Projects’ Descriptions Based on Classname Word Elements,"2022 23rd ACIS International Summer Virtual Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD-Summer)",2022,"In the field of software development, there are many cases where products developed in the past have technical liabilities or are not managed as assets. As a solution to this situation, we are investigating the concept of software upcycling, which converts past products into valuable resources. In order to perform upcycling, the purpose of this paper is to understand the purpose and function of existing projects. Our key idea is to focus on the words that constitute class names. Moreover, examine how useful these words are for inferring the purpose and function of the system. Specifically, we obtain all the class names from the project by repository mining and extract the words that constitute each class file name. We consider the obtained words to reflect the characteristics of the project from which they were extracted. Furthermore, we also conduct a preliminary experiment to verify whether it is possible to infer the purpose and function of the project by referring only to these words.",2
15,Case-based reasoning for software design reuse,2005 IEEE Aerospace Conference,2005,"Object-oriented software development is well known as a concept which allow efficient reuse of software components. Unfortunately, reuse of designs has received very little attention. With regard to reuse issue, several researches apply case-based reasoning (CBR) as their methodology which allows developers to reuse designs of previously developed software. Based on the CBR, reuse is achieved by retrieving a set of similar cases to a given query. Class diagram can be seen as a kind of case representation for design reuse process. This paper discusses an approach that can be used to retrieve class diagrams from case repository. Unlike most of the researches that have been conducted in the field, the novel approach does not only focus on label of classes when finding similar cases. In stead, the system retrieve similar cases or designs by considering number of matching diagram's elements including: class; relationship; direction; and multiplicity of classes. User then selects the most similar cases proposed by the system that suited them In order to produce an output which is ready to be used in most commercial software design tools, the result of matching is a set of class diagrams created by using XML language, which could be displayed in any UML tool. The approach has been implemented in an experimental system call ""EaseDesign"" in which the method clearly improve productivity of software designers",3
16,Neo-piagetian Forms of Reasoning in Software Development Process Construction,2013 Learning and Teaching in Computing and Engineering,2013,"ICT students continue to struggle in their development of fundamental programming skills and software development processes. Crucial to successful mastery is the development of discipline specific cognitive and metacognitive skills, including self-regulation. We can assist our students in the process of reflection and self-regulation by identifying and articulating successful self-regulated learning strategies for specific discipline contexts. However, in order to do so, we must develop an understanding of those discipline specific strategies that can be successful and readily adopted by students, and ways of understanding and articulating successful mental models. In this paper, we explore a Neo-Piagetian analysis of students' reflections upon their software development processes, enabling us to identify mental models for software development. We adopt a case study approach, identifying key examples of pre-operational behaviours that rely upon self-regulated learning strategies in place of articulated mental models, through to formal operational behaviours exhibiting complex, multi-relationship models of software development and design activities. Our study provides support for pedagogy for sharing of mental models and strategies amongst students, and guiding students by explicitly modelling the software development process.",3
17,Modeling and Reasoning with Changing Intentions: An Experiment,2017 IEEE 25th International Requirements Engineering Conference (RE),2017,"Existing modeling approaches in requirements engineering assume that stakeholder goals are static: once set, they remain the same throughout the lifecycle of the project. Of course, such goals, like anything else, may change over time. In earlier work, we introduced Evolving Intentions: an approach that allows stakeholders to specify how evaluations of goal model elements change over time. Simulation over Evolving Intentions enables stakeholders to ask a variety of 'what if' questions, and evaluate possible evolutions of a goal model. GrowingLeaf is a web-based tool that implements both the modeling and analysis components of this approach. In this paper, we investigate the effectiveness and usability of Evolving Intentions, Simulation over Evolving Intentions, and GrowingLeaf. We report on a between-subjects experiment we conducted with fifteen graduate students familiar with requirements engineering. Using qualitative, quantitative, and timing data, we show that Evolving Intentions were intuitive, that Simulation over Evolving Intentions increased the subjects' understanding and produced meaningful results, and that GrowingLeaf was found to be effective and usable.",3
18,Hierarchical case-based reasoning integrating case-based and decompositional problem-solving techniques for plant-control software design,IEEE Transactions on Knowledge and Data Engineering,2001,"Case based reasoning (CBR) is an artificial intelligence technique that emphasises the role of past experience during future problem solving. New problems are solved by retrieving and adapting the solutions to similar problems, solutions that have been stored and indexed for future reuse as cases in a case-base. The power of CBR is severely curtailed if problem solving is limited to the retrieval and adaptation of a single case, so most CBR systems dealing with complex problem solving tasks have to use multiple cases. The paper describes and evaluates the technique of hierarchical case based reasoning, which allows complex problems to be solved by reusing multiple cases at various levels of abstraction. The technique is described in the context of Deja Vu, a CBR system aimed at automating plant-control software design.",52
19,Reasoning about the correctness of software development process,Proceedings of the 24th International Conference on Software Engineering. ICSE 2002,2002,"Summary form only given. During the object-oriented software development process, a variety of models of the system is built. All these models are not independent, but they are related to each other. Elements in one model have trace dependencies to other models; they are semantically overlapping and together represent the system as a whole. It is necessary to have a precise definition of the syntax and semantics of the different models and their relationships, since the lack of accuracy in their definition can lead to wrong model interpretations and inconsistency between models. The paper considers the notion of formal contract regulating the activities in the software development process. It defines the concept of software process contract (sp-contract).",0
20,Incremental Theory Closure Reasoning for Large Scale Knowledge Graphs,IEEE Access,2019,"Knowledge graph(KG)s have become more and more important for the field of cybersecurity. However, they usually contain much implicit semantic information, which needs to be further mined through semantic inference to be more useful for both analysts and automated systems. In this paper, we propose an incremental reasoning algorithm KGRL-Incre for the scenario that the instances of a KG is expanded with only a small set of triples, which can perform an incremental update to the previous reasoning result effectively to avoid a full re-reasoning over the expanded KG. The main contributions of our approach are the irrelevant triple filtering algorithms which reduce the scale of data that need to be processed and a delay reasoning strategy which limits the number of time-consuming iterations while still preserves relative completeness of the final result. The extensive experiments and comprehensive evaluations are conducted and the experimental results show that the KGRL-Incre can significantly reduce time consumption compared with the expanding and reasoning approach in the target scenario.",4
21,Seven layers of knowledge representation and reasoning in support of software development,IEEE Transactions on Software Engineering,1992,"The authors' experience in the Programmer's Apprentice project in applying knowledge representation and automated reasoning to support software development is summarized. A system, called Cake, is described that comprises seven layers of knowledge representation and reasoning facilities: truth maintenance, Boolean constraint propagation, equality, types, algebra, frames, and Plan Calculus. Sessions with two experimental software development tools implemented using Cake, the Requirements Apprentice and the Debugging Assistant, are also included.<>",36
22,“SHORT”er Reasoning About Larger Requirements Models,2017 IEEE 25th International Requirements Engineering Conference (RE),2017,"When Requirements Engineering(RE) models are unreasonably complex, they cannot support efficient decision making. SHORT is a tool to simplify that reasoning by exploiting the ""key"" decisions within RE models. These ""keys"" have the property that once values are assigned to them, it is very fast to reason over the remaining decisions. Using these ""keys"", reasoning about RE models can be greatly SHORTened by focusing stakeholder discussion on just these key decisions.This paper evaluates the SHORT tool on eight complex RE models. We find that the number of keys are typically only 12% of all decisions. Since they are so few in number, keys can be used to reason faster about models. For example, using keys, we can optimize over those models (to achieve the most goals at least cost) two to three orders of magnitude faster than standard methods. Better yet, finding those keys is not difficult: SHORT runs in low order polynomial time and terminates in a few minutes for the largest models.",5
23,Combining iterative analytical reasoning and software development using the visualization language Processing,2009 IEEE Symposium on Visual Analytics Science and Technology,2009,"Processing is a very powerful visualization language which combines software concepts with principles of visual form and interaction. Artists, designers and architects use it but it is also a very effective programming language in the area of visual analytics. In the following contribution Processing is utilized in order to visually analyze data provided by IEEE VAST 2009 Mini Challenge Badge and Network Traffic. The applied process is iterative and each stage of the analytical reasoning process is accompanied by customized software development. The visual model, the process and the technical solution will be briefly introduced.",0
24,A pipelined fuzzy reasoning processor and its software development system,"1995 International Symposium on VLSI Technology, Systems, and Applications. Proceedings of Technical Papers",1995,"Fuzzy reasoning processors have been employed in many commercial and industrial applications. A high-performance pipelined, single-instruction-stream, and single-data-stream architecture of a fuzzy reasoning engine has been designed. Based on this architecture, the proposed VLSI processor for embedded real-time fuzzy logic applications was fabricated in a 0.8-/spl mu/m CMOS technology. Its computation power can reach 2.5 Million Fuzzy Logic Inferences Per Second (MFLIPS) at a system clock of 20 MHz. In order to efficiently realize fuzzy applications, a software development system under Microsoft Windows has also been designed.",0
25,Ontology Based Software Design Documentation For Design Reasoning,2019 Moratuwa Engineering Research Conference (MERCon),2019,"Designing a quality software product adhering to all the functional and non-functional requirements is a challenging task in software architecture designing. Selecting the best designs to apply in the project will be included in the design reasoning. The discussion on the selections are important, but it dies when the discussion ends. The reasoning is important to be documented for maintenance purpose and to accommodate any changes that would result in architectural evolution. There are tools, which have been proposed for this purpose, but, using an ontological approach with implementation and evaluation has not been conducted. Hence an ontology-based approach has been chosen for documenting the software architecture design reasoning under this research. As software designing is a vast area of design decisions, the research was narrowed down to the RESTful web service domain. First, an ontology was created, capturing the key terms and the architectural elements of the domain. A tool was created using this ontology to generate the design reasoning for a given software document. Three techniques were used when creating the tool, which comprised of a key term matching, deriving elements based on parts of speech tagging, and ontology reasoning. The reasoning captured from these techniques will be documented in a user-friendly manner. A prototype of this approach was developed and evaluated to prove its usability and accuracy. The overall precision of 0.58 was calculated with the use of the prototype application developed.",1
26,Combined goal and feature model reasoning with the User Requirements Notation and jUCMNav,2014 IEEE 22nd International Requirements Engineering Conference (RE),2014,"The User Requirements Notation (URN) is an international requirements engineering standard published by the International Telecommunication Union. URN supports goal-oriented and scenario-based modeling and analysis. jUCMNav is an open-source, Eclipse-based modeling tool for URN. This tool demonstration focuses on recent extensions to jUCMNav that have incorporated feature models into a URN-based modeling and reasoning framework. Feature modeling is a well-establishing technique for capturing commonalities and variabilities of Software Product Lines. Combined with URN, it is possible to reason about the impact of feature configurations on stakeholder goals and system qualities, thus helping to identify the most appropriate features for a stakeholder. Furthermore, coordinated feature and goal model reasoning is fundamental to Concern-Driven Development, where concerns are defined with a three-part variation, customization, and usage interface. As the variation interface is described with feature and goal models, it is now possible with jUCMNav to define and reason about a concern's variation interface, which is a prerequisite for composing multiple concerns based on their three-part interfaces.",1
27,Proposal for the Implementation of a Web Platform to Reinforce the Learning of the Mathematical Reasoning Course for Sixth Grade of Primary School,"2023 IEEE XXX International Conference on Electronics, Electrical Engineering and Computing (INTERCON)",2023,"Currently, the traditional teaching methodology used in educational centers is not effectively adapted to the current technological era, which can lead to poor academic performance of students, especially in the subject of mathematical reasoning. The objective of the research is to develop a web platform that reinforces the learning of mathematical reasoning in sixth grade students. For this purpose, the agile software development methodology SCRUM was used, due to its agility and flexibility in the development process. In addition, the Game Learning methodology was used for the development of the web page content. The results obtained by conducting the experiment through a control and experimental group, in addition to the application of a survey, obtained a Spearman’s Rho of 0.891 and a significance of less than 0.05, demonstrating that there is a relationship between the use of the web platform and the learning of mathematical reasoning. Thus, it is demonstrated that the use of ICT (information and communication technologies) benefits students, since it improves in several aspects in relation to traditional teaching, as evidenced in the experiment an improvement of 3.331% of the experimental group compared to the control group. Therefore, it is plausible to conclude that the use of a web platform accompanied by the Game Learning methodology reinforces students’ learning in general.",0
28,A Simple Model for Reasoning about Limits on Coupling in Object-Oriented Software,2020 10th Annual Computing and Communication Workshop and Conference (CCWC),2020,"Given that all of a program's code must be reachable from its main method, and that type-safety causes this reachability to substantially manifest as compilation dependencies among the program's classes, a simple model for reasoning about limits on coupling among a program's classes-a long-standing question in the software design literature-is proposed. The model takes the form of a directed graph with classes as nodes and four distinct forms of compilation dependencies as labeled edges. As manifested in compilation dependencies, the model suggests that there is a trade-off between direct and transitive coupling, and that certain forms of coupling in a class are prerequisites for the existence of other forms in that same class.",0
29,Enabling Analysis and Reasoning on Software Systems through Knowledge Graph Representation,2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR),2023,"This work presents a knowledge-representation-based approach for analysing software systems. Its main components are: a generic and extensible knowledge model, and a knowledge extractor tool that generates instance-level knowledge graphs from software repositories (currently Java). Our knowledge model can be used as a shared data-model in a software analysis pipeline. We illustrate the potential uses of our knowledge representation by performing experimental architecture recovery and identifying design pattern instance. We intend to use our ontology and extraction tool as a partial foundation for automated reasoning on software systems.",1
30,Towards an Automatic Generation of UML Class Diagrams from Textual Requirements using Case-based Reasoning Approach,2022 4th International Conference on Applied Automation and Industrial Diagnostics (ICAAID),2022,"Nowadays automatic information extraction plays a major roles in software development life cycle. It allows producing automated tools that help humans in routine tasks. The automatic extraction of Unified Modeling Language (UML) class diagrams from textual requirements can help in reducing the design time and cost. This paper proposes a novel case-based reasoning model to facilitate the process of generating the UML class diagrams from textual requirements. The result of this work can help on minimizing the manual work, and can be employed to extract other type of information from documents that we cope with during software development life cycle.",0
31,Reasoning on Non-Functional Requirements for Integrated Services,2009 17th IEEE International Requirements Engineering Conference,2009,"We focus on non-functional requirements for applications offered by service integrators; i.e., software that delivers service by composing services, independently developed, managed, and evolved by other service providers. In particular, we focus on requirements expressed in a probabilistic manner, such as reliability or performance. We illustrate a unified approach-a method and its support tools-which facilitates reasoning about requirements satisfaction as the system evolves dynamically. The approach relies on run-time monitoring and uses the data collected by the probes to detect if the behavior of the open environment in which the application is situated, such as usage profile or the external services currently bound to the application, deviates from the initially stated assumptions and whether this can lead to a failure of the application. This is achieved by keeping a model of the application alive at run time, automatically updating its parameters to reflect changes in the external world, and using the model's predictive capabilities to anticipate future failures, thus enabling suitable recovery plans.",17
32,Trust Representation and Reasoning for Access Control in Large Scale Distributed Systems,2007 2nd International Conference on Pervasive Computing and Applications,2007,"The Internet-based large scale distributed applications have huge and changeable user groups, which brings forward a new problem for access control in the systems. The traditional access control methods are identification based and closed, which can not satisfy the new security requirement of the large scale distributed systems. Trust-based access control is dynamically scalable which has provided a new way for solving this problem. Trust representation and reasoning is the fundamental issue in trust-based access control. In this paper, we first analyze the properties of trust in human society, and describe the attributes of trust in the context of access control. Then basing on the fuzzy set theory, we suggest a mathematic model for trust representation and reasoning. An example is given for showing how the model can be used to represent trust.",20
33,KGRL: An OWL2 RL Reasoning System for Large Scale Knowledge Graph,"2016 12th International Conference on Semantics, Knowledge and Grids (SKG)",2016,"Currently knowledge graph has been widely applied to various fields. Although the data scale is large, there is still a lot of useful but implicit information in it. Thus, a powerful reasoning system is required to derive these data. However, current reasoning systems cannot accomplish this task very well. On the one hand, stand-alone reasoning systems cannot meet the demand of large data. On the other hand, the reasoning ability of existing distributed reasoning systems is limited because of the lack of expressive inference rules. In this paper, we propose and implement a distributed reasoning system KGRL for knowledge graph based on OWL2 RL. It has a more powerful reasoning ability due to more expressive rules. It also supports optimization for redundant data. Besides, a rule-based algorithm is designed to find the inconsistent data. Experimental results show that KGRL can derive more implicit information efficiently compared to other reasoning systems. Moreover, KGRL is capable of eliminating redundant data, which can reduce the storage of knowledge graph by an average of 42%. Finally, KGRL also performs well for the detection of inconsistencies in knowledge graph.",7
34,Towards a software diagnosis method based on rough set reasoning,2008 8th IEEE International Conference on Computer and Information Technology,2008,"Software diagnosis for finding faults based on the test results is one of the most time-consuming and labor-intensive activities in large scale software development. Revealing the potential knowledge hidden in the test results or program constructs to assist this activity is a rational solution. In this paper, we propose two kinds of debugging applications based on rough set reasoning. One is to select key input parameters which will affect program’s behaviors to facilitate diagnosis. The other is to extract association rules between program input and its behaviors. The inputs of the above two rough reasoning applications are all the test results of functional testing. Our work is the first attempt to utilize functional testing information to help software debugging. The feasibility and effectiveness of our approach is validated by some examples and experiments. In addition, some on-going research issues are also addressed.",2
35,Rely-Guarantee Reasoning about Messaging System for Autonomous Vehicles,2020 International Symposium on Theoretical Aspects of Software Engineering (TASE),2020,"Messaging system as a communicating infrastructure is a safety-critical component of autonomous vehicles. For the purpose of safety certification of Level 4 autonomous driving systems, its necessary to provide a formally verified specification of messaging systems. This paper presents a realistic case study using the PiCore rely-guarantee framework to formally verify the DGPS (Differential Global Positioning System) of UISEE autonomous driving systems. We first create an axiom model of messaging systems by extending PiCore, which is reusable for concrete applications. The model supports dynamic configuration of message buffers as well as the automatic generation of the rely and guarantee conditions for compositional reasoning. It is instantiated when developing the formal specification of DGPS. Then, we use the rely-guarantee proof system of PiCore to verify the functional correctness and invariant of DGPS. The specification and its proof provide a strong evidence for the ongoing safety certification of DGPS.",0
36,FFL: Fine-grained Fault Localization for Student Programs via Syntactic and Semantic Reasoning,2022 IEEE International Conference on Software Maintenance and Evolution (ICSME),2022,"Fault localization has been used to provide feedback for incorrect student programs since locations of faults can be a valuable hint for students about what caused their programs to crash. Unfortunately, existing fault localization techniques for student programs are limited because they usually consider either the program's syntax or semantics alone. This motivates the new design of fault localization techniques that use both semantic and syntactical information of the program.In this paper, we introduce FFL (Fine grained Fault Localization), a novel technique using syntactic and semantic reasoning for localizing bugs in student programs. The novelty in FFL that allows it to capture both syntactic and semantic of a program is three-fold: (1) A fine-grained graph-based representation of a program that is adaptive for statement-level fault localization; (2) an effective and efficient model to leverage the designed representation for fault-localization task and (3) a node-level training objective that allows deep learning model to learn from fine-grained syntactic patterns. We compare FFL's effectiveness with state-of-the-art fault localization techniques for student programs (NBL, Tarantula, Ochiai and DStar) on two real-world datasets: Prutor and Codeflaws. Experimental results show that FFL successfully localizes bug for 84.6% out of 2136 programs on Prutor and 83.1% out of 780 programs on Codeflaws concerning the top-10 suspicious statements. FFL also remarkably outperforms the best baselines by 197%, 104%, 70%, 22% on Codeflaws dataset and 10%, 17%, 15% and 8% on Prutor dataset, in term of top-1, top-3, top-5, top-10, respectively.",0
37,The Causal Reasoning Ability of Open Large Language Model: A Comprehensive and Exemplary Functional Testing,"2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security (QRS)",2023,"As the intelligent software, the development and application of large language models are extremely hot topics recently, bringing tremendous changes to general AI and software industry. Nonetheless, large language models, especially open source ones, incontrollably suffer from some potential software quality issues such as instability, inaccuracy, and insecurity, making software testing necessary. In this paper, we propose the first solution for functional testing of open large language models to check full-scene availability and conclude empirical principles for better steering large language models, particularly considering their black box and intelligence properties. Specifically, we focus on the model’s causal reasoning ability, which is the core of artificial intelligence but almost ignored by most previous work. First, for comprehensive evaluation, we deconstruct the causal reasoning capability into five dimensions and summary the forms of causal reasoning task as causality identification and causality matching. Then, rich datasets are introduced and further modified to generate test cases along with different ability dimensions and task forms to improve the testing integrity. Moreover, we explore the ability boundary of open large language models in two usage modes: prompting and lightweight fine-tuning. Our work conducts comprehensive functional testing on the causal reasoning ability of open large language models, establishes benchmarks, and derives empirical insights for practical usage. The proposed testing solution can be transferred to other similar evaluation tasks as a general framework for large language models or their derivations.",0
38,Combining Combinatorial Testing and Metamorphic Testing for Testing a Logic-Based Non-monotonic Reasoning System,"2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)",2018,"Combinatorial testing has proven to be a very valuable testing technique for automated generation of test suites given the domain of the inputs and the configuration parameters. In order to fully automate combinatorial testing, however, there is a need for an automated test oracle. In case of testing logic-based non-monotonic reasoning systems, we show how to generate test cases and how to make use of metamorphic testing in order to provide a test oracle. The combined testing method allows for complete test automation. We further discuss first experimental results obtained for an implementation of an assumption-based truth maintenance system implementing basic non-monotonic reasoning capabilities.",4
39,Nòmos 3: Reasoning about regulatory compliance of requirements,2014 IEEE 22nd International Requirements Engineering Conference (RE),2014,The great impact that law has in the RE-process has called for new techniques and procedures to evaluate the alignment of requirements with applicable laws. In this paper we present a modeling language for the evaluation of compliance of requirements with a piece of law: Nòmos 3. We introduce our language and show the reasoning capabilities of our proposal.,5
40,Tool support for combined rule-based and goal-based reasoning in Context-Aware systems,2012 20th IEEE International Requirements Engineering Conference (RE),2012,"Context-aware systems often use rule-based reasoning engines for decision making without involving explicit interaction with the user. While rule-based systems excel in filtering out unsuitable solutions based on clear criteria, it is difficult to rank suitable solutions based on vague, qualitative criteria with a rule-based approach. Moreover, the description of such systems is typically ad-hoc without well-defined modeling tasks. CARGO (Context-Aware Reasoning using Goal-Orientation) aims to address these problems by combining rule-based and goal-based reasoning as well as scenario-based modeling to provide a more comprehensive way to define context-aware systems and to process contextual information. This demo presents CARGO, a modeling, simulation, and execution environment for context-aware systems built on existing tool support for the User Requirements Notation.",5
41,rΣ: Automated reasoning tool for non-functional requirement goal models,2011 IEEE 19th International Requirements Engineering Conference,2011,"Reasoning is critical for non-functional requirements (NFRs) analysis and verification. Furthermore, it can provide rationale about implementation strategies for NFRs. The existing tools can execute an interactive reasoning process which sometimes needs extra information from stakeholders. We build a tool called rΣ for reasoning on NFR models especially when extra information is unavailable or forbidden, like at the model verification stage. This tool employs the formula style model as the input, automatically promotes the reasoning process till the root node, and returns all the satisficing statuses and the complete rationale as the output. We have applied rΣ into the real practice and to evaluate its efficiency.",3
42,Requirements Reasoning for Distributed Requirements Analysis Using Semantic Wiki,2009 Fourth IEEE International Conference on Global Software Engineering,2009,"In large-scale collaborative software projects, thousands of requirements with complex interdependencies and different granularity spreading in different levels are elicited, documented, and evolved during the project lifecycle. Non-technical stakeholders involved in requirements engineering activities rarely apply formal techniques; therefore it is infeasible to automatically detect problems in requirements. This situation becomes even worse in a distributed context when all sites are responsible to maintain their own requirements list using various requirements models and management tools, and the detection of requirements problems across multiple sites is error-prone, and un-affordable if performed manually. This paper proposes an integrated approach of basing distributed requirements analysis on semantic Wiki by requirements reasoning. First, the functions concerning reasoning support provided by semantic Wiki for requirements analysis are proposed. Second, the underlying requirements rationale model for requirements reasoning is presented with sample reasoning rules. Third, our rationale model is mapped to the WinWin requirements negotiation model which further adds to its credibility.",21
43,A ubiquitous system for smart reasoning for well-being at home and at work,2012 IEEE International Conference on Pervasive Computing and Communications Workshops,2012,"The lifestyle of the Dutch workforce is degrading. Unhealthy habits cause both physical and psychological problems, putting a strain on the individual's well-being. In order to conquer both of these, a system will be created that will coach its user to improve their lifestyle through a better diet and promoting physical activity in order to improve their feeling of well-being. However, requirements engineering is troublesome in this domain. We propose ways to conquer these requirements engineering problems using model-driven engineering techniques.",1
44,Supporting quantitative reasoning of non-functional requirements: A process-oriented approach,2012 International Conference on Software and System Process (ICSSP),2012,"A long standing problem in software engineering is inadequate requirements elicitation, analysis, specification, validation and management. The lack of well defined requirements is one of the major causes of project failure. Several well-known techniques and frameworks have been developed to deal with the functional aspect of requirements engineering. Recent years have also seen the emergence of frameworks that incorporate non-functional requirements. The Non-Functional Requirements (NFR) Framework models non-functional requirements and associated implementation methods. This paper presents a process-orientated, lightweight, quantitative extension to the NFR Framework; focusing on providing quantitative support to the decision process and how decisions affect the system.",8
45,Retrieving design patterns by case-based reasoning and Formal Concept Analysis,2009 2nd IEEE International Conference on Computer Science and Information Technology,2009,"Design patterns are applied to solve the recurring software design problems. Unfortunately, choosing appropriate design patterns for the specific design problem is considered a difficult task. A search tool is, therefore, needed to supports selection. However, the existing design pattern searching methodologies generally have problems on keyword-search problem. In this paper, we proposed an initial model to solve the problem by using Case-Based Reasoning (CBR) and Formal Concept Analysis (FCA). For the proposed model, a case base is created to represent design patterns. FCA is used to be case organization that analyze case base for obtain knowledge embedded. The knowledge can suggest suitable indexes to use for new problem. This method is beneficial for learning index. This paper discusses the basis theoretical of representation and retrieval design patterns for this inprogress research, along with some preliminary result.",9
46,Mobile Ontology-based Reasoning and Feedback (MORF) Health Monitoring System,2008 Third International Conference on Digital Information Management,2008,"Over the past few years many medical professionals have shifted their focus to ubiquitous health monitoring systems. With continuous advancements in both bio-medical and information technologies, such futuristic monitoring systems have become a present reality. When intermixed with ubiquitous computing, a mobile health monitoring system provides unrestrained potential and innumerable applications. This research aims to improve upon and advance beyond modern medical monitoring systems by incorporating ontology-based reasoning to make the system independent and automated. In this paper, we present the main features of our ubiquitous mobile health monitoring system, its hardware and software design, and potential applications.",2
47,Reasoning with Inconsistent OWL Ontologies for Software Reuse,2009 WRI World Congress on Software Engineering,2009,"A framework for reasoning with inconsistent OWL ontologies is presented with the aim to support the design of Software design patterns. The priority information between axioms are given explicitly, allowing for the use of pieces of information having various levels of confidence, a preferential semantics is then defined for reasoning with prioritized ontology, the property of the method is studied, and the reasoning algorithms is given.",1
48,Use of Case-Based Reasoning to Automate the Testing of Electronic Forms,2023 Sixth International Conference of Women in Data Science at Prince Sultan University (WiDS PSU),2023,"The digital transformation increases the usage of electronic forms (e-forms). Every e-form has its fields with specific validation requirements. Testing the field’s validity of the input is required to improve the performance. However, manual testing is time consuming and requires efforts. Hence, automating this task can reduce efforts, time, and costs. In this research study, we propose a software that tests e-forms fields’ validations using the well-known AI technique called Case-Based Reasoning (CBR). The integration of CBR contributes to easily collecting the validations requirements for each field. This software helps in raising quality and reducing testing time and efforts. It includes the registration and contact us e-forms, which are the most commonly used types of e-forms. We demonstrated the efficiency of CBR in testing the registration and contact us e-forms. Moreover, the proposed software shows promising results in terms of precision (about 96% for the registration e-form and 95% for the contact us e-form) compared to the manual testing (about 82% and 91% respectively).",0
49,Dependence directed reasoning and learning in systems maintenance support,IEEE Transactions on Software Engineering,1988,"The maintenance of large information systems involves continuous modifications in response to evolving business conditions or changing user requirements. Based on evidence from a case study, it is shown that the system maintenance activity would benefit greatly if the process knowledge reflecting the teleology of a design could be captured and used in order to reason about he consequences of changing conditions or requirements, A formalism called REMAP (representation and maintenance of process knowledge) that accumulates design process knowledge to manage systems evolution is described. To accomplish this, REMAP acquires and maintains dependencies among the design decisions made during a prototyping process, and is able to learn general domain-specific design rules on which such dependencies are based. This knowledge cannot only be applied to prototype refinement and systems maintenance, but can also support the reuse of existing design or software fragments to construct similar ones using analogical reasoning techniques.<>",32
50,Planning Software Project Success with Semi-Quantitative Reasoning,2007 Australian Software Engineering Conference (ASWEC'07),2007,"Software process modeling and simulation hold out the promise of improving project planning and control. However, purely quantitative approaches require a very detailed understanding of the software project and process, including reliable and precise project data. Contemporary project management defines the success of project as a box or hyper-cube, rather than the traditional single point, which allows the planning for software project success semi-quantitatively with uncertainty-tolerance. This paper introduces semi-quantitative reasoning into software project planning and develops a practical approach to enhance the confidence of project success under the uncertainty and contingency. We illustrate its value and flexibility by a simplified software process model focusing on staffing issues.",4
51,Combining MaxSAT Reasoning and Incremental Upper Bound for the Maximum Clique Problem,2013 IEEE 25th International Conference on Tools with Artificial Intelligence,2013,"Recently, MaxSAT reasoning has been shown to be powerful in computing upper bounds for the cardinality of a maximum clique of a graph. However, existing upper bounds based on MaxSAT reasoning have two drawbacks: (1)at every node of the search tree, MaxSAT reasoning has to be performed from scratch to compute an upper bound and is time-consuming, (2) due to the NP-hardness of the MaxSAT problem, MaxSAT reasoning generally cannot be complete at anode of a search tree, and may not give an upper bound tight enough for pruning search space. In this paper, we propose an incremental upper bound and combine it with MaxSAT reasoning to remedy the two drawbacks. The new approach is used to develop an efficient branch-and-bound algorithm for MaxClique, called IncMaxCLQ. We conduct experiments to show the complementarity of the incremental upper bound and MaxSAT reasoning and to compare IncMaxCLQ with several state-of-the-art algorithms for MaxClique.",30
52,Reasoning about concurrent objects,Proceedings 1995 Asia Pacific Software Engineering Conference,1995,"Embedded specifications in object-oriented (OO) languages such as Eiffel and Sather are based on a rigorous approach towards validation, compatibility and reusability of sequential programs. The underlying method of ""design-by-contract"" is based on Hoare logic for which concurrency extensions exist. However concurrent OO languages are still in their infancy. They have inherently imperative facets, such as object identity, sharing, and synchronisation, which cannot be ignored in the semantics. Any marriage of objects and concurrency requires a trade-off in a space of intertwined qualities. The paper summarises our work on a type system, calculus and an operational model for concurrent objects in a minimal extension of the Eiffel and Sather languages (cSather). We omit concurrency control constructs and instead use assertions as synchronisation constraints for asynchronous functions. We show that this provides a framework in which subtyping and concurrency can coexist.",4
53,A pipelined fuzzy reasoning processor with software development system and its application on the crane control problem,"1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century",1995,"Fuzzy reasoning processors have been employed in many commercial and industrial applications. A high-performance pipelined, single-instruction-stream, and single-data-stream architecture of fuzzy reasoning engine has been designed. Based on this architecture, the proposed VLSI processor for embedded real-time fuzzy logic applications was fabricated in an 0.8-/spl mu/m CMOS technology. Its computation power can reach 2.5 million fuzzy logic inferences per second (MFLIPS) at a system clock of 20 MHz. In order to efficiently realize fuzzy applications, a software development system under Microsoft Windows has also been designed. For the purpose of showing its effectiveness, we have carried out the experiments to successfully control the crane system. Experimental results have shown the efficient cooperative control of the proposed fuzzy reasoning processor with software development system and can be contrast with conventional computer software interface control.",1
54,The application of case-based reasoning to early Web project cost estimation,Proceedings 26th Annual International Computer Software and Applications,2002,"Literature shows that over the years numerous techniques for estimating development effort have been suggested, derived from late project measures. However, to the successful management of software projects, estimates are necessary throughout the whole development life cycle. The objective is twofold. First, we describe the application of case-based reasoning (CBR) for estimating Web hypermedia development effort using measures collected at different stages in the development cycle. Second, we compare the prediction accuracy of those measures, obtained using different CBR configurations. Contrary to the expected, late measures did not show statistically significant better predictions than early measures.",22
55,Using an Architecture Reasoning Tool to Teach Software Architecture,20th Conference on Software Engineering Education & Training (CSEET'07),2007,"The Architecture Expert (ArchE) is a software architecture design assistant under development at the Software Engineering Institute (SEI). It embodies knowledge of quality attributes and the relation between the achievement of quality attribute requirements and architecture design. In this paper, we describe the use of ArchE in a graduate level software architecture class at Clemson University. The discussion combines aspects of using ArchE as a tool to produce architectures and using ArchE to teach about architecting. The students were positive about the use of ArchE although critical of ArchE's immaturity. The instructor was also positive about the use of ArchE.",6
56,"On Reasoning within Different Domains in the Past, Present and Future",2012 23rd International Workshop on Database and Expert Systems Applications,2012,"The foundations and technologies of Case-Based Reasoning (CBR) has emerged from academic projects to commercial used applications which are supporting everyday life. Everything changes in the long term which includes planning, modeling and developing reasoning software due to new aspects such as big data and various new services provided by cloud computing. Maintaining a balance between achieving the requirements and maximizing the return on investment of a software application can be seen as a difficult task. In this paper we will present the evolution of CBR software over the past years in order to gain an understanding concerning some crucial points when creating a CBR system.",2
57,Employing Expert Opinion and Software Metrics for Reasoning About Software,"Third IEEE International Symposium on Dependable, Autonomic and Secure Computing (DASC 2007)",2007,"When comparing software programs based on certain qualities there is usually more than one metric that can be used. Often these metrics may contradict one another or there may be no standard acceptance thresholds. In this work we demonstrate how the Analytical Hierarchy Process (AHP) can be used to mitigate the aforementioned deficiencies in metrics-based software decision making. We illustrate the procedure by incorporating value judgments from a group of experts into an existing metrics data set to rank the design complexity in three imaging software packages. In this case the injection of expert opinion in a formalized framework minimizes the problems associated with conflicting metrics. The contribution of this work is to demonstrate how a combination of expert opinion and tool-collected measures can be used to reason about software programs. The methodology employed can be easily modified to include different metrics, applications and weights, thus providing a practical assessment tool for decision making about software.",1
58,Software process modeling using object-oriented programming and rule-based reasoning,Proceedings of AUTOTESTCON '94,1994,"In the context of software process modeling (process definition and simulation), this paper presents an object-oriented programming and rule-based reasoning method to simulate a part of an existing software process model. Presently, our process simulation emphasizes process training and enactment. That is, the simulation is on the ""what and how"" portion of the model.<>",0
59,Modeling constraints improves software architecture design reasoning,2009 Joint Working IEEE/IFIP Conference on Software Architecture & European Conference on Software Architecture,2009,"Requirements and project-related factors influence architectural design in intricate and multivariate ways. We are only beginning to understand some of the tacit but fundamental mechanisms involved in reasoning about design decisions, and one of them concerns the role of design constraints. This paper examines design constraints and how they shape design solutions. We introduce a design constraint model and an architectural design reasoning process for specifying design constraints and checking for design conflicts. We experiment with using logic for constraint verification with the alloy tool.",6
60,Approximate reasoning about software models,"IEEE Annual Meeting of the Fuzzy Information, 2004. Processing NAFIPS '04.",2004,"This article introduces an approximating reasoning approach to evaluating models for system design relative to a system design standard. A fundamental problem in system design is that feature values extracted from experimental design models tend not to match exactly patterns associated with standard design models. It is not generally known how to measure the extent that a particular system design conforms to a standard design pattern. The rough set approach introduced by Zdzislaw Pawlak provides a basis for concluding to what degree a particular model for a system design is a part of a set of a set of models representing a standard. Sample models exhibiting selected behavioral design patterns are briefly considered by way of illustration of design model approximation. In this paper, an approximation space for design patterns is introduced. In addition, an approach to the satisfaction-based classification of design models is also presented.",0
61,Formalization of multiagent reasoning,Proceedings. International Conference on Parallel Computing in Electrical Engineering,2002,"The paper presents a new formal language for describing multiagent systems, which are collections of interacting, autonomous agents. The research work includes the description of the fundamental features of agents (processes) as well as the way they communicate with each other. The language defined in the paper allows describing the properties of systems such as deadlock, termination, and fairness. Two main results are presented for the defined logic: non-compactness of the semantic consequence relation and the lack of the deduction theorem. The article is an introduction to further research.",0
62,A Electric Network Reconfiguration Strategy with Case-Based Reasoning for the Smart Grid,2019 8th Brazilian Conference on Intelligent Systems (BRACIS),2019,"The complexity, heterogeneity and scale of electrical networks have grown far beyond the limits of exclusively human-based management at the Smart Grid (SG). Likewise, researchers cogitate the use of artificial intelligence and heuristics techniques to create cognitive and autonomic management tools that aim better assist and enhance SG management processes like in the grid reconfiguration. The development of self-healing management approaches towards a cognitive and autonomic distribution power network reconfiguration is a scenario in which the scalability and on-the-fly computation are issues. This paper proposes the use of Case-Based Reasoning (CBR) coupled with the HATSGA algorithm for the fast reconfiguration of large distribution power networks. The suitability and the scalability of the CBR-based reconfiguration strategy using HATSGA algorithm are evaluated. The evaluation indicates that the adopted HATSGA algorithm computes new reconfiguration topologies with a feasible computational time for large networks. The CBR strategy looks for managerial acceptable reconfiguration solutions at the CBR database and, as such, contributes to reduce the required number of reconfiguration computation using HATSGA. This suggests CBR can be applied with a fast reconfiguration algorithm resulting in more efficient, dynamic and cognitive grid recovery strategy.",2
63,System of Systems for Tripwires Activation of Algorithms and Reasoning (STAAR) for Analysis of Mission Success,2018 13th Annual Conference on System of Systems Engineering (SoSE),2018,"The flood of data from Multi-Intelligence sources (e.g., air and space sensors, street cameras, and social media) is overwhelming mission operators who manually or semi-autonomously ingest and make decisions on these data. This data glut is driving the development of Systems of Systems (SoS) solutions that exhibit emergent behavior evolving to fully autonomous methods that allow end users to focus on critical data first in order to make timely decisions and assure mission success.",0
64,Semantic Network Model: A Reasoning Engine for Software Requirements,2015 20th International Conference on Engineering of Complex Computer Systems (ICECCS),2015,"In this paper, we present a semantic network model (SNM) as a reasoning engine for the requirements models. The SNM consists of the vertices and the edges, in which they store information of the models and their interrelations. The SNM, through a semi-automated normalisation process, helps the user (1) to assign states to the models and their relations as to whether they can be included, excluded, or undecided, (2) to eliminate redundant interrelations, (3) to avoid over-specification, and (4) to visualise a simplified overview of the whole system. Finally, we formulate the well-formedness of the SNM, which indicates whether the given models can produce a formal specification. We also evaluate our techniques using several case studies.",1
65,Using Ontology Reasoning in Building a Simple and Effective Dialog System for a Smart Home System,"2015 IEEE International Conference on Systems, Man, and Cybernetics",2015,"This paper presents a dialog system for the user in interacting with a smart home system. Instead of using just a voice control for appliances, a dialog system gives the user a more natural way of communication with the smart home. The dialog system can take different forms of instruction from the user and provides services to the user. The user can inquire the system about some information instead of just ordering appliances to operate. With a dialog system, the system can also give a more informative response to the user. This paper focuses on processing the semantic information from the user input and producing a set of clear service request to send to the service provider. By limiting the application to a smaller set of services, we introduce an ontology reasoning technique to construct a simple dialog system that accepts explicit and implicit user requests. Two different kinds of ontology, the home ontology and the family member ontology, are constructed. A prototype system is presented along with demonstration using scenarios to show the result of our work.",4
66,Meta-reasoning for a distributed agent architecture,Proceedings of the 33rd Southeastern Symposium on System Theory (Cat. No.01EX460),2001,"Agent based computing offers the ability to decentralize computing solutions by incorporating autonomy and intelligence into cooperating, distributed applications. It provides an effective medium for expressing solutions to problems that involve interaction with real-world environments and allows modelling of the world state and its dynamics. This model can be then used to determine how candidate actions affect the world and how to choose the best from a set of actions. Most agent paradigms overlook real-time requirements and computing resource constraints. We discuss the application of agent based computing to RoboCup and examine methods to improve it. In particular, we discuss the incorporation of a meta-level reasoning mechanism that handles individual agent organization, plan generation, task allocation, integration and plan execution. We also propose an architecture where a meta-agent is further enhanced by combining it with system-level resource allocation and optimization. The approach adopted by us unifies agent based computing with adaptive resource management for dynamic real-time systems. The goal is to build and implement a distributed, intelligent, agent based system for dynamic real-time applications.",2
67,A neural network case-based reasoning and its application,Proceedings. International Conference on Machine Learning and Cybernetics,2002,"An important factor that plays a major role in determining the performance of a case-based system is the complexity and the accuracy of the case retrieval phase. The nearest neighbor search, knowledge-based method and the inductive approach all suffer from serious drawbacks. This paper examines the possibility of using neural networks as a method of retrieval in such case-based systems. A simple efficient case-based system structure is constructed with neural networks. Also, some algorithms are proposed and tested. The application results show that the approach is efficient.",2
68,An application of Bayesian reasoning to improve functional test diagnostic effectiveness,"Proceedings, IEEE AUTOTESTCON",2002,"This paper describes a software package that embodies a Bayesian reasoning engine and modeling schema to significantly improve the ability to discern the defective component causing a failed functional test. This software approach brings to functional test similar diagnostic capabilities that have become familiar to test engineers working with X-ray, automatic optical inspection (AOI) and in-circuit test (ICT) test technologies. This software package, known as Fault Detective, provides significantly improved diagnostic accuracy as compared to human efforts, and works with exactly the same data set as is currently available for diagnostic purposes. The model is based on the interaction of the functional test suite with the product functional block diagram. This approach also means that the software package is highly independent of the technology behind the system being diagnosed.",1
69,Case-based reasoning in software engineering,IEE Colloquium on Case-Based Reasoning,1993,"Case-based reasoning provides a new and revealing perspective for the reuse of system specifications during requirements engineering. The authors examine case-based reasoning with old specifications during requirements engineering using complex examples of requirements reuse and case studies of observed successful case-based reuse. Intelligent tool support for requirements engineering needs domain knowledge to develop and validate requirements specifications. The authors propose a paradigm for specification reuse which exploits the different skills and domain knowledge possessed by software engineers and support tools. A similar approach has also been implemented in several case-based reasoning tools. An intelligent advisor, known as AIR, has been designed and implemented to assist reuse of old specification cases.<>",2
70,A logical framework for modeling and reasoning about the evolution of requirements,Proceedings of ISRE '97: 3rd IEEE International Symposium on Requirements Engineering,1997,"We present a logical framework for modeling and reasoning about the evolution of requirements. We demonstrate how a sufficiently rich meta level logic can formally capture intuitive aspects of managing changes to requirements models, while maintaining completeness and consistency. We consider a theory as the deductive closure of a given set of axioms and conclude that software engineering is concerned, in essence, with, building and managing large theories. This theory construction commences with the development of the requirements model which we view as a theory of some nonmonotonic logic. Requirements evolution then involves the mapping of one such theory to another. Exploiting the deductive power of the theory of belief revision and nonmonotonic reasoning we develop a formal description of this mapping, as well as the requirements engineering process itself. This work thus offers a rigorous approach to reasoning about requirements evolution and a important focus for defining semantically well founded methods and tools for the effective management of changing requirements.",51
71,On requirements representation and reasoning using answer set programming,2014 IEEE 1st International Workshop on Artificial Intelligence for Requirements Engineering (AIRE),2014,"We describe an approach to the representation of requirements using answer set programming and how this leads to a vision for the role of artificial intelligence techniques in software engineering with a particular focus on adaptive business systems. We outline how the approach has developed over several years through a combination of commercial software development and artificial intelligence research, resulting in: (i) a metamodel that incorporates the notion of runtime requirements, (ii) a formal language for their representation and its supporting computational model (InstAL), and (iii) a software architecture that enables monitoring of distributed systems. The metamodel is the result of several years experience in the development of business systems for e-tailing, while InstAL and the runtime monitor is on-going research to support the specification, verification and application of normative frameworks in distributed intelligent systems. Our approach derives from the view that in order to build agile systems, the components need to be structured more like software that controls robots, in that it is designed to be relatively resilient in the face of a non-deterministic, dynamic, complex environment about which there is incomplete information. Thus, degrees of autonomy become a strength and an opportunity, but must somehow be constrained by informing these autonomous components what should be done in a certain situation or what system state ought to be achieved through norms as expressions of requirements. Because such a system made up of autonomous components is potentially behaviourally complex and not just complicated, it becomes essential to monitor both whether norms/requirements are being fulfilled and if not why not. Finally, because control over the system can be expressed through requirements in the form of data that can be changed, a route is opened to adjustment and dynamic re-direction of running systems.",3
72,Combined propagation-based reasoning with goal and feature models,2014 IEEE 4th International Model-Driven Requirements Engineering Workshop (MoDRE),2014,"The User Requirements Notation (URN) is an international requirements engineering standard published by the International Telecommunication Union. URN supports goal-oriented and scenario-based modeling as well as analysis. Feature modeling, on the other hand, is a well-establishing technique for capturing commonalities and variabilities of Software Product Lines. When combined with URN, it is possible to reason about the impact of feature configurations on stakeholder goals and system qualities, thus helping to identify the most appropriate features for a stakeholder. Combined reasoning of goal and feature models is also fundamental to Concern-Driven Development, where concerns are composed not only based on functionality expressed with feature models, but also based on impact on stakeholder goals. Therefore, an analysis technique for feature and goal models based on a single conceptual model is desirable, because of its potential to streamline model analysis and reduce the complexity of the analysis framework. This paper introduces such a technique, i.e., a single, propagation-based reasoning algorithm that supports combined reasoning of goal and feature models and offers additional usability improvements over existing goal-oriented reasoning mechanisms.",1
73,Automated reasoning for derivation of products in MD-SPLE,2011 6th Colombian Computing Congress (CCC),2011,"This article presents a strategy that aims to support model-oriented software product line architects on making the decisions required to derive products. Together with the strategy, we present a tool that uses the power of constraint programming to create and use decision models. The models make it possible to relate model transformation rules and product line variants (alternatives) in order to enable the selection of the necessary rules according to the variants selected by a product designer. The greatest innovation of our contribution is that we provide architects with a tool that takes into account the possible interactions between variants of a product line and makes it possible to model the decisions required to derive products reusing existing model transformation rules as much as possible.",0
74,DeepWeak: Reasoning common software weaknesses via knowledge graph embedding,"2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)",2018,"Common software weaknesses, such as improper input validation, integer overflow, can harm system security directly or indirectly, causing adverse effects such as denial-of-service, execution of unauthorized code. Common Weakness Enumeration (CWE) maintains a standard list and classification of common software weakness. Although CWE contains rich information about software weaknesses, including textual descriptions, common sequences and relations between software weaknesses, the current data representation, i.e., hyperlined documents, does not support advanced reasoning tasks on software weaknesses, such as prediction of missing relations and common consequences of CWEs. Such reasoning tasks become critical to managing and analyzing large numbers of common software weaknesses and their relations. In this paper, we propose to represent common software weaknesses and their relations as a knowledge graph, and develop a translation-based, description-embodied knowledge representation learning method to embed both software weaknesses and their relations in the knowledge graph into a semantic vector space. The vector representations (i.e., embeddings) of software weaknesses and their relations can be exploited for knowledge acquisition and inference. We conduct extensive experiments to evaluate the performance of software weakness and relation embeddings in three reasoning tasks, including CWE link prediction, CWE triple classification, and common consequence prediction. Our knowledge graph embedding approach outperforms other description- and/or structure-based representation learning methods.",33
75,ReFixar: Multi-version Reasoning for Automated Repair of Regression Errors,2021 IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE),2021,"Software programs evolve naturally as part of the ever-changing customer needs and fast-paced market. Software evolution, however, often introduces regression bugs, which un-duly break previously working functionalities of the software. To repair regression bugs, one needs to know when and where a bug emerged from, e.g., the bug-inducing code changes, to narrow down the search space. Unfortunately, existing state-of-the-art automated program repair (APR) techniques have not yet fully exploited this information, rendering them less efficient and effective to navigate through a potentially large search space containing many plausible but incorrect solutions. In this work, we revisit APR on repairing regression errors in Java programs. We empirically show that existing state-of-the-art APR techniques do not perform well on regression bugs due to their algorithm design and lack of knowledge on bug inducing changes. We subsequently present ReFixar, a novel repair technique that leverages software evolution history to generate high quality patches for Java regression bugs. The key novelty that empowers ReFixar to more efficiently and effectively traverse the search space is two-fold: (1) A systematic way for multi-version reasoning to capture how a software evolves through its history, and (2) A novel search algorithm over a set of generic repair templates, derived from the principle of incorrectness logic and informed by both past bug fixes and their bug-inducing code changes; this enables ReFixar to achieve a balance of both genericity and specificity, i.e., generic common fix patterns of bugs and their specific contexts. We compare ReFixar against the state-of-the-art APR techniques on a data set of 51 real regression bugs from 28 large real-world programs. Experiments show that ReFixar significantly outperforms the best baseline by a large margin, i.e., ReFixar can fix correctly 24 bugs while the best baseline can only correctly fix 9 bugs.",2
76,Analyzing the non-functional requirements to improve accuracy of software effort estimation through case based reasoning,2015 10th International Conference on Intelligent Systems: Theories and Applications (SITA),2015,"Producing accurate software effort estimation is essential for effective software project management that remains a considerable challenge to software engineering and software industry in general. Many methods have been proposed to increase the accuracy of estimating the software project size, effort, or cost. However, the primary focus has been on functional requirements FRs. We are convinced that the rigorous estimation requires a thorough knowledge of all the requirements of the software to be measured. Consequently, a clear identification of the FRs and NFRs as well as a strong understanding of the relationships existing between them is crucial to get measurements closer to reality. In this paper, we propose an early software size and effort estimation method based on a combination of COSMIC and case based reasoning that uses individual requirement measurements as a solution to improve the performance of CBR and to increase the precision of the estimations. This hybrid technique consists in adjusting the FRs measurements by the effect of NFRs with which they are connected. A new link requirements model is proposed in which the possible relationships existing between FRs and NFRs are expressed. This combination will help to efficiently include NFRs, and their relations with FRs, earlier in the measurement process and throughout the life cycle of the software development project.",3
77,Sidekicks and Superheroes: A Look into Student Reasoning about Concurrency with Threads versus Actors,2020 IEEE/ACM 42nd International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET),2020,"When computations consist of different processes or threads that may execute at the same time or in an interleaved manner, we say the computation is concurrent or that it exhibits concurrency. University students often struggle to reason about concurrency. Researchers have presented students with natural language descriptions of scenarios involving concurrency and have evaluated students' natural language responses to explore their prior knowledge and to determine characteristics of student reasoning about concurrency. However, natural language responses are necessarily abstract and pertain to the design stage of software development, while studies in which students are asked to implement solutions provide a more concrete view of student reasoning and reveal difficulties that arise when putting design into practice. In this work we build upon prior work and ask: What are common and problematic features in student approaches to solving concurrency-related problems? How do these features differ from the design phase to the implementation phase of the software development life cycle? In this study we asked students enrolled in a jointly offered upper division undergraduate / MS level course on “Programming with Concurrency” to implement a solution to the same problem (a side-kick/superhero version of the party matching problem) using two different approaches: Threads-based in Java, and Actors-based in Scala. We performed qualitative feature analysis of their implementations and their written reflections to better understand student reasoning when programming concurrent solutions. The feature of additional complexity was found in our earlier natural language study in which students described their designs. Additional complexity was also represented in student implementations in this study and adversely impacted student success as their programs became cumbersome and hard to trace. Student reflections provided insight into their resistance to modeling prior to implementation, and indicated that they found formal modeling techniques difficult. These findings suggest that lighter weight interventions that address student difficulties earlier in the development process may be more palatable to students and thus have substantial impact.",0
78,Rationalism with a dose of empiricism: Case-based reasoning for requirements-driven self-adaptation,2014 IEEE 22nd International Requirements Engineering Conference (RE),2014,"Requirements-driven approaches provide an effective mechanism for self-adaptive systems by reasoning over their runtime requirements models to make adaptation decisions. However, such approaches usually assume that the relations among alternative behaviours, environmental parameters and requirements are clearly understood, which is often simply not true. Moreover, they do not consider the influence of the current behaviour of an executing system on adaptation decisions. In this paper, we propose an improved requirements-driven self-adaptation approach that combines goal reasoning and case-based reasoning. In the approach, past experiences of successful adaptations are retained as adaptation cases, which are described by not only requirements violations and contexts, but also currently deployed behaviours. The approach does not depend on a set of original adaptation cases, but employs goal reasoning to provide adaptation solutions when no similar cases are available. And case-based reasoning is used to provide more precise adaptation decisions that better reflect the complex relations among requirements violations, contexts, and current behaviours by utilizing past experiences. Our experimental study with an online shopping benchmark shows that our approach outperforms both requirements-driven approach and case-based reasoning approach in terms of adaptation effectiveness and overall quality of the system.",20
79,Transforming regulations into performance models in the context of reasoning for outcome-based compliance,2013 6th International Workshop on Requirements Engineering and Law (RELAW),2013,"Recently, interest in performance modeling of out-come-based regulations has grown in the regulatory community. In this context, performance modeling refers to the measuring of important business aspects in a coordinated manner and the use of these measurements for improved decision making. Goal modeling techniques have shown to be beneficial when expressing and analyzing performance models. Since most regulations are still written in natural language, support for the transformation of regulatory text into performance models is needed. This allows regulators and regulated parties to keep working with familiar natural language regulations and to use goal models indirectly while avoiding a potentially significant learning curve for goal-modeling techniques. In this paper, we present such a tool-supported transformation to goal models expressed with the User Requirements Notation that enables reasoning about outcome-based regulations via widely available evaluation mechanism for goal models. The transformation is implemented in the jUCM-Nav goal modeling tool and illustrated with an example from the banking domain.",9
80,A hybrid model for agile practices using case based reasoning,2013 IEEE 4th International Conference on Software Engineering and Service Science,2013,"Agile Software Development works as the bridge that establishes the path to handle changes in the composite task of Software Development. In this research, we present a hybrid model which has been introduced for evolution of the Agile Software Development Practices by using Artificial Intelligence (AI) technique. The methods we used in this research are published reports, articles and existing case studies. Expert's response method is applied to accomplish the appraisal of this model. This model has resulted in improving the Agile Practices by using the concept of Case Based Reasoning (CBR). The model provides a guideline to the Agile Software Development regarding enhancement of Agile Practices incorporated with CBR.",7
81,AnalyticGraph.com: Toward Next Generation Requirements Modeling and Reasoning Tools,2016 IEEE 24th International Requirements Engineering Conference (RE),2016,"Graphical Requirements Modeling (GRM) consists of representing requirements in diagrams: requirements (and other relevant information) are represented as nodes, and relationships between them as edges. Relationships can show, for example, that one requirement refines another, that some are in conflict with others, that they are more or less desirable, and so on. Various software tools have been proposed over the years as a support to doing GRM, some capable of performing computations over diagrams, such as searching for text strings, or determining if a requirement is satisfied (and how much). We present yet another tool, available at AnalyticGraph.com. The tool departs from much of prior work in the following ways. (i) The tool is a web application, is available on-demand, and requires no installation of specialized software. (ii) Each model made with the tool gets its own permanent and unique URL, so that models can be linked in research papers. (iii) If a model on AnalyticGraph is linked in a paper, then any reader can click on the link, open a free account, and edit and run a copy of the linked model. (iv) The tool supports the definition of various requirements modeling languages. (v) Models are stored in a graph database, and standard graph queries (such as find the shortest path between two nodes) are included by default. (vi) It is possible to combine models made with various languages, and do computations over the resulting mixed models.",3
82,Applying knowledge representation and reasoning to (simple) goal models,2014 IEEE 1st International Workshop on Artificial Intelligence for Requirements Engineering (AIRE),2014,"We consider simple i∗-style goal models with influence (contribution) links and AND/OR refinement (decomposition), and formalize them by translation into three standard logics that are actively studied in AI Knowledge Representation and Reasoning (KR&R): propositional logic, FOL and description logics (the first formalization is well known). In each case, this provides a semantics for the notation, on which we can base the definition of forward (“what if?”) and backward (“how is this achievable?”) reasoning, of interest to requirements engineers. We consider the manner in which AI KR&R research provides off-the-shelf algorithms that can be used to solve these tasks. We compare the representations by reporting known worst-case complexity results for the reasoning, as well as other criteria such as size/understandability of axiomatization, and ease of extension of modeling language.",3
83,Semantic web representations for reasoning about applicability and satisfiability of federal regulations for information security,2015 IEEE Eighth International Workshop on Requirements Engineering and Law (RELAW),2015,"In this paper, the Nomos 2 framework for modeling law-compliant solutions in software system design is applied in the context of the Federal Information Security Modernization Act (FISMA) of 2014. Information security regulatory statements with a high variability space are examined to explore the utility and limits of the Nomos 2 framework for information security regulations. Additionally, Nomos 2 concepts are modeled in a semantic web representation for reasoning about the applicability and satisfiablity of FISMA regulations for information systems. The use of freely available semantic web toolsets for knowledge modeling and reasoning are demonstrated in an example scenario requiring the determination of FISMA related authorities and functions.",1
84,Automated Reasoning towards Quantitative Security Assurance,2019 IEEE 10th International Conference on Software Engineering and Service Science (ICSESS),2019,"System security assurance has become one of the most important research directions in software engineering and requirement engineering. To date, a lot of approaches have been proposed to conduct system security assurance. However, in these existing approaches, the constraint conditions of security assurance are rarely mentioned. In software engineering domain, constraint is a critical factor that can affect the success or failure of the engineering project, and thus the practicability of these approaches may be called in question. In order to resolve this problem, this paper proposes a new security assurance method that allows engineers to give consideration to both contribution attributes and cost attributes for security objectives during system architecture design process. In addition, a recursive algorithm is proposed and implemented to realize automated reasoning for developing security assurance cases.",0
85,Applying Case-Based Reasoning to software requirements specifications quality analysis system,The 2nd International Conference on Software Engineering and Data Mining,2010,"Software Requirements Specifications (SRS) or software requirements are basically an organization's understanding of a customer's system requirements and dependencies at a given point in time. This research paper focuses only on the requirements specifications phase of the software development cycle (SDC). It further narrows it down to analyzing the quality of the prepared SRS to ensure that the quality is acceptable. It is a known fact that companies will pay less to fix problems that are found very early in any software development cycle. The Software Quality Assurance (SQA) audit technique is applied in this study to determine whether or not the required standards and procedures within the requirements specifications phase are being followed closely. The proposed online quality analysis system ensures that software requirements among others are complete, consistent, correct, modifiable, ranked, traceable, unambiguous, and understandable. The system interacts with the developer through a series of questions and answers session, and requests the developer to go through a checklist that corresponds to the list of desirable characteristics for SRS. The Case-Based Reasoning (CBR) technique is used to evaluate the requirements quality by referring to previously stored software requirements quality analysis cases (past experiences). CBR is an AI technique that reasons by remembering previously experienced cases.",4
86,A role for chunking and fuzzy reasoning in a program comprehension and debugging tool,Proceedings Ninth IEEE International Conference on Tools with Artificial Intelligence,1997,"We are applying artificial intelligence techniques to develop a tool called BUG-DOCTOR that assists software engineers with program comprehension and debugging. In this paper we describe two of BUG-DOCTOR's knowledge sources, the Chunker and the Plan Processor. The Chunker identifies candidate chunks in the target code using program analysis techniques and a set of heuristics. Candidate chunks map to higher level concepts, and have a signature which captures their major identifying characteristics. The Plan Processor uses a signature to retrieve a set of program plans from a Plan Library with features that are similar to those of the candidate chunk. Its fuzzy reasoner then ranks the retrieved plans. The plan chosen as most similar to the candidate chunk is used for program comprehension and debugging tasks that follow. We believe that this approach could lead to more scalable tools for program comprehension and debugging.",7
87,A System Based on Ontology and Case-Based Reasoning to Support Distributed Teams,2015 12th International Conference on Information Technology - New Generations,2015,"The intrinsic nature of distributed software development (DSD) brings new challenges, such as communication issues and sharing information efficiently. Software companies have a tendency to face these challenges using individual and isolated approaches, making difficult to spread good practices for the DSD community. In other contexts, concepts and techniques from Artificial Intelligence (AI) are frequently used in order to improve the functioning of systems and process. This work is based on the following AI concepts: ontologies, case-based reasoning (CBR) and natural language processing (NLP). We propose a system, based on ontology and case-based reasoning, that operates as follows: i) we use a tool for ontology storage, access and processing; and ii) an ontology-based CBR tool which aims to aid software companies by recommending techniques and best practices for minimizing or solving potential challenges that may be faced by DSD processes. The main results from this research are: i) a specific ontology for distributed software development teams; ii) a tool to facilitate the access and manipulation of the proposed ontology; and iii) a case based reasoning system that utilizes natural language processing. Initial results of the performed experiments indicate a success rate of 91.7% in the recommendation of solutions for potential problems coming from DSD processes.",1
88,Reasoning in agent-based network management,NOMS 2018 - 2018 IEEE/IFIP Network Operations and Management Symposium,2018,"An increasing complexity of mobile networks and use cases is reflected in requirements for network management. Advanced automation is required to address this challenge in an economically feasible manner. We describe a system based on agent mapping as a platform for automation for network management in 5G networks and beyond. We use classical and probabilistic reasoning for composing solutions to complex re­quests by means of relatively simple software agents. We describe different variants of the approach in terms of capabilities, ranging from triple store only to system with semantic and probabilistic reasoning functionalities. This approach provides flexibility for network functionality evolution and facilitates software reuse and is compatible with the use of task-specific machine learning algorithms in network management agents. We describe test system used for evaluating the concept, as well as use case evaluation obtained with it.",1
89,Software-Friendly Subjective Bayesian Networks: Reasoning within a Software-Centric Mission Impact Assessment Framework,2023 26th International Conference on Information Fusion (FUSION),2023,"Subjective Bayesian networks (SBN) combine Bayesian Networks (BN) with Subjective Logic in order to express the second-order uncertainty (i.e., the uncertainty about a probability distribution of an event – as opposed to the uncertainty about the event itself). While SBNs provide a strong formalism for treating the uncertainty in a higher level, the literature lacks support for extensive software implementations focused on compatibility with current software solutions or standards. Our work explores the structural congruence between BN and SBN (in terms of software data structure) and a semantic bijection between Subjective Logic opinions to Dirichlet distributions to introduce a SBN reasoning framework that targets on effectively reusing the existing BN solutions. Particularly, we developed two inference algorithms that apply a Monte Carlo method to existing BN inference algorithms (we chose the Junction Tree algorithm, for test), respectively for batch and interactive SBN reasoning. A method for translating an evidence in SBN to uncertain (virtual) evidence in BN is also presented. The main contribution of this paper is the introduction of a simple, yet flexible empirical estimation method and a software architecture that virtually adapts any BN inference algorithm to an approximate computational inference framework for SBN. We also developed a Java component to demonstrate the reusability, and we developed a case study of Mission Impact Assessment of Unmanned Aerial Vehicles transporting critical items between hospitals in order to illustrate the applicability in a knowledge engineering process.",0
90,Use of case-based reasoning techniques for intelligent computer-aided-design systems,Proceedings of IEEE Systems Man and Cybernetics Conference - SMC,1993,"Reuse of designs is an important research direction for the future intelligent CAD systems. The main applications of such a research are various, from mechanical systems design (spacecraft, robot, ...) to software design. This paper will present a survey of the use of case-based reasoning (CBR) techniques for intelligent CAD systems in order to reuse designs or parts of designs. First, we will briefly resume some work issued from cognitive psychology, showing the importance of analogical-reasoning for design activities and then the origins of the CBR technology in AI. Second, we will then present the main systems using case-based reasoning for design activities followed by a comparative analysis between these systems. To conclude, we will indicate the main directions in CBR for design and will propose to adopt a cognitive approach from knowledge acquisition until the development of real design support systems.<>",6
91,Reasoning about adaptive requirements for self-adaptive systems at runtime,2011 2nd International Workshop on Requirements@Run.Time,2011,"Increasing proliferation of mobile applications challenge the role of requirements engineering (RE) in developing customizable and adaptive software applications for the end-users. Such adaptive applications need to alter their behavior while monitoring and evaluating the changes in the environment at runtime by being aware of their end-user's needs, context and resources. More specifically, these applications should be able to: (i) reason about their own requirements and refine and validate them at run-time by involving end-users, if necessary; (ii) provide solutions for the refined or changed requirements at runtime, for instance by exploiting available services. In this position paper we focus on the first issue. We propose to extend our previous work on adaptive requirements with preference-based reasoning and automated planning to enable a continuous adaptive reasoning of requirements at runtime. We describe this vision using a navigation system example and highlight challenges.",11
92,Towards Symbolic Pointers Reasoning in Dynamic Symbolic Execution,2021 Ivannikov Memorial Workshop (IVMEM),2021,"Dynamic symbolic execution is a widely used technique for automated software testing, designed for execution paths exploration and program errors detection. A hybrid approach has recently become widespread, when the main goal of symbolic execution is helping fuzzer increase program coverage. The more branches symbolic executor can invert, the more useful it is for fuzzer. A program control flow often depends on memory values, which are obtained by computing address indexes from user input. However, most DSE tools don’t support such dependencies, so they miss some desired program branches.We implement symbolic addresses reasoning on memory reads in our dynamic symbolic execution tool Sydr. Possible memory access regions are determined by either analyzing memory address symbolic expressions, or binary searching with SMT-solver. We propose an enhanced linearization technique to model memory accesses.Different memory modeling methods are compared on the set of programs. Our evaluation shows that symbolic addresses handling allows to discover new symbolic branches and increase the program coverage.",5
93,A Novel Case Base Reasoning and Frequent Pattern Based Decision Support System for Mitigating Software Risk Factors,IEEE Access,2020,"Software risk management is crucial for the success of software project development. The existing literature has models for risk management, but is too complex to be used in practice. The information in the existing studies is scattered over different articles which makes it difficult to find relevant knowledge to establish relationship between risk factors and mitigations. This paper presents a novel model which identifies the relationship between risk factors and mitigations automatically by using intelligent Decision Support System (DSS). The proposed model has four steps. Firstly, the input of the system has been designed where risk factors and mitigations have been inputted into it. Secondly, rule based machine learning approach has been used for mining of associations between risks and mitigations. Thirdly, Case Based Reasoning (CBR) approach has been used to determine the previous cases as rules. Finally, automated rules have been generated to develop an intelligent DSS to mitigate the software risks. The proposed technique copes with the highly cited existing limitations of risk handling like, lack of generic DSS and intelligent relationship between software risks and mitigations. Automated rules have been discovered with a novel idea of CBR and frequent pattern. The proposed model is capable of mitigating upcoming risks in future. Star schema has been implemented to support our proposed DSS. Moreover, from highly cited literature 40 studies were identified from which 26 risk factors, 57 mitigations, 14 questions and 26 automated rules have been extracted. According to the validation of IT industry experts, the average of the effectiveness of DSS is 51-55%. The novelty of the proposed research is that it uses two state of the art methods (Rule Based Machine Learning and CBR) to identify software risk mitigations. The results of the proposed model show that the chances of risks in software development have been reduced significantly.",15
94,Using Interactive Visual Reasoning to Support Sense-Making: Implications for Design,IEEE Transactions on Visualization and Computer Graphics,2013,"This research aims to develop design guidelines for systems that support investigators and analysts in the exploration and assembly of evidence and inferences. We focus here on the problem of identifying candidate 'influencers' within a community of practice. To better understand this problem and its related cognitive and interaction needs, we conducted a user study using a system called INVISQUE (INteractive Visual Search and QUery Environment) loaded with content from the ACM Digital Library. INVISQUE supports search and manipulation of results over a freeform infinite 'canvas'. The study focuses on the representations user create and their reasoning process. It also draws on some pre-established theories and frameworks related to sense-making and cognitive work in general, which we apply as a 'theoretical lenses' to consider findings and articulate solutions. Analysing the user-study data in the light of these provides some understanding of how the high-level problem of identifying key players within a domain can translate into lower-level questions and interactions. This, in turn, has informed our understanding of representation and functionality needs at a level of description which abstracts away from the specifics of the problem at hand to the class of problems of interest. We consider the study outcomes from the perspective of implications for design.",10
95,Positive-Negative Receptive Field Reasoning for Omni-Supervised 3D Segmentation,IEEE Transactions on Pattern Analysis and Machine Intelligence,2023,"Hidden features in the neural networks usually fail to learn informative representation for 3D segmentation as supervisions are only given on output prediction, while this can be solved by omni-scale supervision on intermediate layers. In this paper, we bring the first omni-scale supervision method to 3D segmentation via the proposed gradual Receptive Field Component Reasoning (RFCR), where target Receptive Field Component Codes (RFCCs) is designed to record categories within receptive fields for hidden units in the encoder. Then, target RFCCs will supervise the decoder to gradually infer the RFCCs in a coarse-to-fine categories reasoning manner, and finally obtain the semantic labels. To purchase more supervisions, we also propose an RFCR-NL model with complementary negative codes (i.e., Negative RFCCs, NRFCCs) with negative learning. Because many hidden features are inactive with tiny magnitudes and make minor contributions to RFCC prediction, we propose Feature Densification with a centrifugal potential to obtain more unambiguous features, and it is in effect equivalent to entropy regularization over features. More active features can unleash the potential of omni-supervision method. We embed our method into three prevailing backbones, which are significantly improved in all three datasets on both fully and weakly supervised segmentation tasks and achieve competitive performances.",0
96,Using default reasoning to discover inconsistencies in natural language requirements,Proceedings Eighth Asia-Pacific Software Engineering Conference,2001,"The use of logic in identifying and analysing inconsistency in requirements from multiple stakeholders has been found to be effective in a number of studies. Default reasoning is a theoretically well founded formalism that is especially suited for supporting the evolution of requirements. However, direct use of logic in eliciting requirements and in discussing them with stakeholders poses serious useability problems. In this paper we explore the integration of natural language parsing techniques with default reasoning to overcome these difficulties. We also propose a method for automatically discovering scenarios that expose inconsistencies in requirements, and show how to deal with them in a formal manner. These techniques were implemented and tested in a prototype tool called CARL.",15
97,A tool for reasoning about software models,COMPASS '93: Proceedings of the Eighth Annual Conference on Computer,1993,The authors describe a tool for supporting formal reasoning about software systems via their specification diagrams. The formal interconnection analysis tool (FIAT) is meant to help bridge the technology gap between the broad software engineering community and the community of researchers and practitioners of formal methods. An environment was developed for describing and reasoning about software by means of three mechanisms: a graphical interconnection language; a tabular component behavior specification language; and a repository of existing component definitions. The mechanisms are described. The verification process-the kinds of queries that the tool can process and the algorithm for processing the queries-is outlined. Some plans to extend the capabilities of FIAT are discussed.<>,0
98,Reasoning about time in higher-level language software,IEEE Transactions on Software Engineering,1989,"A methodology for specifying and providing assertions about time in higher-level-language programs is described. The approach develops three ideas: the distinction between, and treatment of, both real-time and computer times; the use of upper and lower bounds on the execution times of program elements; and a simple extension of Hoare logic to include the effects of the passage of real-time. Schemas and examples of timing bounds and assertions are presented for a variety of statement types and programs, such as conventional sequential programs including loops, time-related statements such as delay, concurrent programs with synchronization, and software in the presence of interrupts. Examples of assertions that are proved include deadlines, timing invariants for periodic processes, and the specification of time-based events such as those needed for the recognition of single and double clicks from a mouse button.<>",232
99,An Ontology-Based Approach to Software Comprehension - Reasoning about Security Concerns,30th Annual International Computer Software and Applications Conference (COMPSAC'06),2006,"There exists a large variety of techniques to detect and correct software security vulnerabilities at the source code level, including human code reviews, testing, and static analysis. In this article, we present a static analysis approach that supports both the identification of security flaws and the reasoning about security concerns. We introduce an ontology-based program representation that lets security experts and programmers specify their security concerns as part of the ontology. Within our tool implementation, we support complex queries on the underlying program model using either predefined or user-defined concepts and relations. Queries regarding security concerns, such as exception handling, object accessibility etc. are demonstrated in order to show the applicability and flexibility of our approach",13
100,Reflection and Reasoning Mechanisms for Failure Detection and Recovery in a Distributed Robotic Architecture for Complex Robots,Proceedings 2007 IEEE International Conference on Robotics and Automation,2007,"Complex robots that interact naturally with humans require the integration, coordination and maintenance of many diverse software components and algorithms. An architecture that incorporates explicit knowledge about the relationships among these components and the overall system state can be used for introspection and consequently to reason about the best configurations of the computing environment under changing conditions; potential uses include maintaining the system's integrity, promoting its health, and providing the ability to dynamically reconfigure system components (e.g., after component failure). In this paper, we describe a rudimentary reasoning system, part of our distributed integrated affect reflection cognition (DIARC) architecture for human-robot interaction, that can autonomously perform failure detection, failure recovery, and system reconfiguration of distributed architectural components to ensure sustained operation and interactions. We demonstrate the functionality and utility of the proposed mechanisms on a robot, where architectural components are forcefully removed by hand and automatically recovered by the system while the robot is continuing its interactions with humans as part of a joint human-robot task.",11
101,A hybrid knowledge representation as a basis of requirement specification and reasoning,[1990] Proceedings of the 2nd International IEEE Conference on Tools for Artificial Intelligence,1990,"A hybrid knowledge representation technique is presented which is used as a basis of a requirement specification language FRORL, (frame-and-rule oriented requirements specification language). To easily represent the structure and behavior of a software system, the syntax of FRORL is based on the concepts of frames and production rules. The semantic interpretation of the FRORL language is defined using Horn-clause logic augmented with the concept of multiple inheritance. The completeness and soundness of the hybrid knowledge representation technique are proved. Based on the full machinery of Horn-clause logic, the FRORL specification modeling the world can be checked against the known constraints of a given domain, and the known facts pertaining to the software system.<>",3
102,An application of fuzzy reasoning to support automated program comprehension,Proceedings Seventh International Workshop on Program Comprehension,1999,"We are developing a knowledge based program understanding/fault localization system called BUGDOCTOR. We describe a system knowledge source called the Plan Processor that retrieves a set of program plans from a plan library using indices called signatures. We propose use of a fuzzy reasoning component to support the Plan Processor with the task of ranking the retrieved plans in order of similarity to the target code. The most similar plan can then be used for the complex plan/code matching required for automated program understanding. Our approach to plan processing may eliminate the need for exhaustive plan library searches, and could lead to automated program understanders that scale up for use on large software systems.",1
103,Knowledge representation and reasoning in the design of composite systems,IEEE Transactions on Software Engineering,1992,"The design process that spans the gap between the requirements acquisition process and the implementation process, in which the basic architecture of a system is defined, and functions are allocated to software, hardware, and human agents. is studied. The authors call this process composite system design. The goal is an interactive model of composite system design incorporating deficiency-driven design, formal analysis, incremental design and rationalization, and design reuse. They discuss knowledge representations and reasoning techniques that support these goals for the product (composite system) that they are designing, and for the design process. To evaluate the model, the authors report on its use to reconstruct the design of two existing composite systems rationally.<>",49
104,Visual tools for temporal reasoning,Proceedings 1993 IEEE Symposium on Visual Languages,1993,"We describe a prototype toolkit for reasoning about Graphical Interval Logic (GIL) specifications of concurrent systems. GIL is a visual temporal logic that is intended to be more intuitive and easier to use than standard textual temporal logics. The GIL toolkit helps system designers to create graphical specifications of concurrent systems, to verify properties of those systems from their specifications, and to generate models that satisfy the specifications. The toolkit provides a visual interface with specifications, proofs, and models all depicted graphically. The paper describes the toolkit, discusses its implementation, and provides an illustration of its use.<>",6
105,Web-Based Intelligent CSCW Exploiting Context-Based Reasoning,2008 IEEE International Conference on Signal Image Technology and Internet Based Systems,2008,"In order to make CSCW (computer supported cooperative works) more intelligent and dependable, the usefulness of contextual reasoning is discussed in this paper. To ensure the project objectives are met, a project manager (PM) maintaining control of the project plays much important roles in complex projects where interaction may be limited to a web-based collaborative tool. In such limitations, he should more strongly help avoid cost overruns, shipment delays, but most importantly, product performance including product reliability. We utilize context-based reasoning (CxBR) for implementing such control measures as typically used by competent PMs. A rocket development project is used as the domain to evaluate our technique, using NASA¿s open software for rocket design. Through the experimental evaluation, the easiness of validation and refinement of Knowledge represented by CxBR is clarified. As well, this Knowledge representation is expected to be effective even for building a web-based complex and intelligent CSCW system where biological sensor fusions are included for situational assessment to aim at the further reliable collaboration support that can avoid such as misunderstanding, mishearing, etc.",1
106,Logic in computer science: tool-based modeling and reasoning about systems,30th Annual Frontiers in Education Conference. Building on A Century of Progress in Engineering Education. Conference Proceedings (IEEE Cat. No.00CH37135),2000,"Recent years have brought about the development of powerful tools for verifying specifications of hardware and software systems. By now, major companies, such as Intel, IBM, AT&T, Siemens, and BT have realized the impact and importance of such tools in their own design and implementation processes as a means of coping with the ever-increasing complexity of chip and software designs. This necessitates the availability of a basic formal training that allows undergraduate students to gain sufficient proficiency in using and reasoning with such tool-animated frameworks. We present an existing course, ""Logical Foundations of Programming"", that aims at meeting these educational goals. After describing inherent challenges that such a course faces, we then evaluate this course in the larger context of what logical frameworks, if any, should be taught and where they may be placed in a computer science related undergraduate curriculum.",0
107,Enhancing predictive maintenance architecture process by using ontology-enabled Case-Based Reasoning,2021 IEEE International Symposium on Systems Engineering (ISSE),2021,"A common milestone in systems architecture development is the logical architecture. It provides a detailed overview of the system components and their interfaces but keeps the architecture as generic as possible, meaning that no component is bound to a specific technology. Subsequently, the architect searches for physical/informational components to fulfill the logical architecture and can apply structured creativity to look for innovative solutions. This search can turn out to be a difficult and long-lasting task depending on the system complexity. Too many options may be available to fulfill the logical system components and not always the most suitable ones are identified. This problem is for instance encountered in the design of new predictive maintenance systems, especially when selecting the components to carry out the diagnostics and prognostics. The current study proposes to support the choice of suitable components combining case-based reasoning and ontologies. A domain ontology has been developed as a terminology framework to support the case base, case structure and similarity measures for a case-based reasoning Decision Support System (DSS). The DSS uses attributes of the new problem to solve and suggests the most similar cases from past experiences. The retrieved solutions can be adapted to develop a new predictive maintenance architecture. The decision support system has been tested with data coming from proved predictive maintenance solutions documented in scientific publications.",1
108,JAMES: Normalizing Job Titles with Multi-Aspect Graph Embeddings and Reasoning,2023 IEEE 10th International Conference on Data Science and Advanced Analytics (DSAA),2023,"In online job marketplaces, it is important to establish a well-defined job title taxonomy for various downstream tasks (e.g., job recommendation, users’ career analysis, and turnover prediction). Job Title Normalization (JTN) is such a cleaning step to classify user-created non-standard job titles into normalized ones. However, solving the JTN problem is non-trivial with challenges: (1) semantic similarity of different job titles, (2) non-normalized user-created job titles, and (3) large-scale and long-tailed job titles in real-world applications. To this end, we propose a novel solution, named JAMES, that constructs three unique embeddings (i.e., graph, contextuat, and syntactic) of a target job title to effectively capture its various traits. We further propose a multi-aspect co-attention mechanism to attentively combine these embeddings, and employ neural logical reasoning representations to collaboratively estimate similarities between messy job titles and normalized job titles in a reasoning space. To evaluate JAMES, we conduct comprehensive experiments against ten competing models on a large-scale real-world dataset with over 350,000 job titles. Our experimental results show that JAMES significantly outperforms the best baseline by 10.06% in Precision@10 and by 17.52% in NDCG@10, respectively. To further facilitate the acquisition of normalized job titles for job-domain applications, our JAMES API is available at: https://tinyurl.con JAMES-job-title-mapping.",0
109,"Case study of digital innovation process improvement, using BPMN, case-based reasoning, and text mining",2022 16th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS),2022,"Managers of digital products frequently receive feature requests from customers, end users, C-suite executives, and other company officials. They need to collect, process, and implement such requests to implement the most valuable features. Moreover, it is often difficult to decide which requests should be applied. The product backlog prioritization strategy is a well-known method widely utilized to enhance this process. However, it is time-consuming because of the large amount of data and is also subject to the human factor. Moreover, the current literature lacks models allowing automated recommendations to help speed up feature request processing, especially for digital startups with a lack of resources. In this paper, we used BPMN to illustrate a case study of redesigning an innovation process in a digital startup. Furthermore, based on the To-Be Process model, we created an approach to recommend new features using case-based reasoning and text mining.",0
110,Optimal Reasoning of Goals in the i* Framework,2015 Asia-Pacific Software Engineering Conference (APSEC),2015,"Requirement analysis involves elicitation of suitable functions or operations and relevant data to support software. A requirement analyst examines different alternative options to decide on an optimal alternative option that benefits the stakeholders of the system. The decision making of alternative design option is complicated by the unavailable or incomplete and imprecise input data. Optimisation, an operation research technique, can be used as a method to solve this problem. The goal-oriented framework, such as i* is used to present social models for the analysis of a software system during the early phase of the requirement's engineering process. This paper aims to develop an optimisation model for the i* goal models, using multi-objective optimisation. The optimisation model aims to fully automate the goal analysis and to handle large goal models. A simulation for the proposed approach was developed by integrating Visual C++ with Matlab and was evaluated with case studies from the existing literature. The evaluation results show that the proposed approach is feasible and offers guidance in the decision making of alternative options.",1
111,An Effective and Efficient Exact Match Retrieval Scheme for Symbolic Image Database Systems Based on Spatial Reasoning: A Logarithmic Search Time Approach,IEEE Transactions on Knowledge and Data Engineering,2006,"In this paper, a novel method of representing symbolic images in a symbolic image database (SID) invariant to image transformations that is useful for exact match retrieval is presented. The relative spatial relationships existing among the components present in an image are perceived with respect to the direction of reference and preserved by a set of triples. A distinct and unique key is computed for each distinct triple. The mean and standard deviation of the set of keys computed for a symbolic image are stored along with the total number of keys as the representatives of the corresponding image. The proposed exact match retrieval scheme is based on a modified binary search technique and, thus, requires O (logn) search time in the worst case, where n is the total number of symbolic images in the SID. An extensive experimentation on a large database of 22,630 symbolic images is conducted to corroborate the superiority of the model. The effectiveness of the proposed representation scheme is tested with standard testbed images",12
112,Data structure repair using goal-directed reasoning,"Proceedings. 27th International Conference on Software Engineering, 2005. ICSE 2005.",2005,"Data structure repair is a promising technique for enabling programs to execute successfully in the presence of otherwise fatal data structure corruption errors. Previous research in this field relied on the developer to write a specification to explicitly translate model repairs into concrete data structure repairs, raising the possibility of 1) incorrect translations causing the supposedly repaired concrete data structures to be inconsistent, and 2) repaired models with no corresponding concrete data structure representation. We present a new repair algorithm that uses goal-directed reasoning to automatically translate model repairs into concrete data structure repairs. This new repair algorithm eliminates the possibility of incorrect translations and repaired models with no corresponding representation as concrete data structures.",12
113,Reasoning about software architecture-based regression testing through a case study,29th Annual International Computer Software and Applications Conference (COMPSAC'05),2005,"Two main issues need to be covered when dealing with the dependability of component-based systems: quality assurance of reusable software components and quality assurance of the assembled component-based system. By focussing on the assembly, a software architecture specification of a component-based system allows to explicitly model the structure and required system behavior by specifying how components and connectors are intended to interact. Software architecture-based conformance testing techniques can yield confidence on the implementation conformance to expected structural and behavioral properties as specified in the architectural models. In this paper we explore software architecture-based regression testing methods that enable reuse of earlier saved results to test if a different assembly of components conforms to the evolved software architecture. The approach is presented through a running example.",7
114,Compositional software reuse with case-based reasoning,Proceedings of 9th IEEE Conference on Artificial Intelligence for Applications,1993,"Case-based reasoning can be applied to software reuse. The approach presented goes beyond furnishing a library of potentially reusable modules and provides a tool that supports the process of reusing software. It uses case-based reasoning to add flexibility and adaptability to the compositional model of reuse. The authors describe the structure of the case base, emphasizing the case acquisition process during which high level functional information is associated with its components. The system performs advanced data-flow analysis of source code to guide acquisition of the functional specification of a library of software modules. The system then decomposes a user's problem, retrieves matching cases, and adapts and assembles their code. The data-flow of the result is again analyzed to produce test cases which can be used to evaluate the success of case-based reasoning.<>",5
115,Better reasoning about software engineering activities,Proceedings 16th Annual International Conference on Automated Software Engineering (ASE 2001),2001,"Software management oracles often contain numerous subjective features. At each subjective point, a range of behaviors is possible. Stochastic simulation samples a subset of the possible behaviors. After many such stochastic simulations, the TAR2 treatment learner can find control actions that have (usually) the same impact despite the subjectivity of the oracle.",5
116,The Calculator Project-formal reasoning about programs,Proceedings Software Education Conference (SRIG-ET'94),1994,"This paper describes the Calculator Project, which was a three-year joint research project between the Centre for Information Technology in Education at The Open University, U.K. and the Department of Computer Science, QMW, University of London, U.K.. The project was funded by the U.K. Joint Council Initiative in Cognitive Science and Human-Computer Interaction. The central aim of the project was to test the hypothesis that providing so-called calculators would improve students performance in those parts of the undergraduate first-year that relied on formal reasoning skills.<>",3
117,Using tracing to direct our reasoning about distributed programs,[1991] Proceedings. 11th International Conference on Distributed Computing Systems,1991,"Two principles are proposed for proving and tracing distributed programs: it is necessary to assert in proofs only what can be readily traced, and trace just what can be asserted in the proofs. A proof system and tracing strategy are described for CSP programs based on these principles, using vector time and control variables, not auxiliary variables, to represent control state, and stressing local rather than global reasoning.<>",2
118,Improving functional/diagnostic testing using model-based reasoning,1998 IEEE AUTOTESTCON Proceedings. IEEE Systems Readiness Technology Conference. Test Technology for the 21st Century (Cat. No.98CH36179),1998,"The most difficult and time-consuming portion of test program development is the diagnostic element. Because of this difficulty, diagnostics are often foregone in the production/maintenance test environment This results in a rework pile of test items that usually become scrapped because manual troubleshooting is too labor-intensive and available technician time is too scarce. A solution to this dilemma is to implement diagnostics in the production/maintenance test environment using a simplified approach: model-based diagnostic reasoning. This paper will describe how to use model-based diagnostics to uncouple the diagnostic logic from the test logic. It will describe how design and test data can be merged to form a Diagnostic Knowledge Base (DKB) The Diagnostician, a commercial off the shelf (COTS) software tool, works with the DKB as part of the test program. The Diagnostician provides the model-based reasoning at runtime. This will allow the unit under test (UUT) design changes to be easily implemented into the diagnostic test program without extensive software changes. By having a different DKB for each revision level, diagnostics can be performed by keying on the revision of the UUT with the same test program.",2
119,6th ICSE workshop on component-based software engineering: automated reasoning and prediction,"25th International Conference on Software Engineering, 2003. Proceedings.",2003,"Component-based technologies and processes have been deployed in many organizations and in many fields over the past several years. However, modeling, reasoning about, and predicting component and system properties remains challenging in theory and in practice. CBSE6 builds on previous workshops in the ICSE/CBSE series, and in 2003 is thematically centered on automated composition theories. Composition theories support reasoning about, and predicting, the runtime properties of assemblies of components. Automation is a practical necessity for applying composition theories in practice. Emphasis is placed in this workshop on composition theories that are well founded theoretically, are verifiable or falsifiable, automated by tools, and supported by practical evaluation.",1
120,Joint Visual Perception and Linguistic Commonsense for Daily Events Causality Reasoning,2022 IEEE International Conference on Multimedia and Expo (ICME),2022,"Multimodal networks that juxtapose visual and linguistic modalities are currently widely adopted for solving vision-and-language tasks. They perform well in simple and intu-itive tasks, but are prone to mistakes in tasks involving latent or implicit details, due to the difficulty of capturing crucial but imperceptible visual signals in the real world. Perception errors lead to nonsensical results, but can be corrected by commonsense knowledge. To this end, we combine visual perception and linguistic commonsense to solve the challenging daily events causality reasoning task. We propose a novel Object-Aware Reasoning Network to focus on object inter-action while ignoring distracting information to refine visual perception. Further, a language branch with an independent prediction head is supervised to learn causality commonsense to help correct obvious perception errors, resulting in more plausible conclusions. Extensive experiments demonstrate that our method achieves new state-of-the-art results on Vis-Causal dataset.",0
121,A framework of software requirements quality analysis system using case-based reasoning and Neural Network,"2012 6th International Conference on New Trends in Information Science, Service Science and Data Mining (ISSDM2012)",2012,"In this paper, we propose a new approach to Software Requirements Specifications (SRS) or software requirements quality analysis process. We apply the Software Quality Assurance (SQA) audit technique in determining whether or not the required quality standards within the requirements specifications phase are being followed closely. Quality analysis of the SRS is performed to ensure that the software requirements among others are complete, consistent, correct, modifiable, ranked, traceable, unambiguous, and understandable. Here, a new approach that combines case-based reasoning (CBR) and neural network techniques in analyzing SRS quality is proposed. This approach is used in improving the process of analyzing the quality of a given SRS document for a specific project. The CBR technique is used to evaluate the requirements quality by referring to previously stored software requirements quality analysis cases (past experiences). CBR is an artificial intelligence technique that reasons by remembering previously experienced cases, and this technique will speed up the quality analysis process. Neural Network (Artificial Neural Network or ANN) is the type of information processing paradigm that is inspired by the way biological nervous systems (brain) process information. Neural network technique works well with CBR because it also uses examples to solve problems. The new approach proposed in this research aims at enhancing and improving existing methods in analyzing SRS quality. A framework of the proposed approach is the main outcome of this research study.",1
122,Reasoning on Requirements Knowledge to Support Creativity,2009 Second International Workshop on Managing Requirements Knowledge,2009,"Developing innovative products is an important challenge for companies these days. Meanwhile it is in requirements engineering widely recognized that requirements elicitation has to go beyond mere recording of knowledge, rather is has to be an active process where new ideas are created. Thus, creativity is an important issue in requirements engineering. While so far tool support for creativity focused mainly on recording the creative outcome or providing relevant knowledge, we will describe an approach where tool support is used to actively support people in the creation of ideas.",4
123,From AutomationML to ROS: A model-driven approach for software engineering of industrial robotics using ontological reasoning,2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA),2016,"One of the major investment for applying industrial robots in production resides in the software development, which is an interdisciplinary and heterogeneous engineering process. This paper presents a novel model-driven approach that uses AutomationML as modeling framework and ontological reasoning as inference framework for constructing robotic application using Robot Operating System (ROS). We show how different robotic components can be classified and modeled with AutomationML, how these components can be composed together to a production system, and how the AutomationML models can be processed semantically by utilizing Semantic Web technologies and ontological reasoning. By applying model-to-text transformation techniques, executable ROS code can be generated from the models that foster fast prototyping and the reuse of robotic software.",21
124,Verification of C Programs Using Automated Reasoning,Fifth IEEE International Conference on Software Engineering and Formal Methods (SEFM 2007),2007,"Much of the embedded software development market has necessarily tight constraints on program size and processor power, hence developers use handwritten C rather than autocode. They rely primarily on testing to find errors in their code. We have an established software development tool known commercially as Perfect Developer, which uses a powerful automatic theorem prover and inference engine to reason about requirements and specifications. We have found that automated reasoning can be used to discharge a very high proportion of verification conditions arising from the specification and refinement of software components described in our formal specification language, Perfect. The Perfect Developer tool set can also generate code in a C++ subset or in Java, and the output code is then virtually certain to meet the stated specification, reducing the need for exhaustive testing. However, this is not helpful to developers of embedded software who are constrained to write code by hand. We therefore decided to investigate whether automated reasoning could provide a similar degree of success in the verification of annotated C code. We present our preliminary findings.",10
125,"Automating programming via concept mining, probabilistic reasoning over semantic knowledge base of SE domain",2010 6th Central and Eastern European Software Engineering Conference (CEE-SECR),2010,"Software engineering is at the very start of it's automation. There are a lot of helpers, code-generators, IDE-s and so on that does not really help to automate the complete software development life-circle from Functional requirements specification till the actual code. We explore the idea to generate the actual software solution using standard Functional requirements specification, change request or bug-report in three main modules: linguistic, perceiving and solution generation with heavily used knowledge base in OWL (web ontology language).",3
126,Software Project Profitability Analysis Using Temporal Probabilistic Reasoning,2008 Advanced Software Engineering and Its Applications,2008,"Providing viable estimates, understanding project requirements and doing proper risk management on software projects require extensive application and sophisticated techniques of analysis and interpretation. There is still a lack of informative techniques and feedback mechanisms that help to assess how well and efficiently a specific development methodology is performing. Analyzing project tasks would enhance how well individual tasks are estimated, how well they are defined, and whether items are completed on-time and on-budget. In this work, we propose a temporal probabilistic model that addresses feedback control mechanisms in project planning using the complex adaptive systems software engineering framework (CASSE). We have tested our approach in industry with a software development company in South Africa on two commercial project evaluations. Our preliminary results show that the temporal probabilistic model of the framework demonstrably enhances practitionerspsila understanding in managing software projects profitably - hence increasing business sustainability and management.",2
127,Intelligent Diagnostic Reasoning System deployment process and results,2008 IEEE AUTOTESTCON,2008,"Lockheed Martin Simulation, Training & Support (LM STS) has developed an Intelligent Diagnostic Reasoning System (IDRS) that can reduce the time and cost to diagnose a failure by isolating to the fault more quickly and reducing callout ambiguity. IDRS uses engineering knowledge and historical test and maintenance data to develop diagnostic models enabling intelligent decision support. IDRS models and services are based on the IEEE 1232trade Artificial Intelligence Exchange and Service Tie to All Test Environment (AI-ESTATE) standard. IDRS is deployed at Ogden Air Logistics Center (OO-ALC) through a partnership between LM STS and OO-ALC 309th Maintenance Wing (309 MXW) Software Maintenance Group and Electronics Maintenance Group at Hill Air Force Base. This paper will outline the selection of the Line Replaceable Unit (LRU), the deployment of IDRS, the results obtained, and the benefits of IDRS.",1
128,Fish diseases control system using case-based reasoning,2010 International Conference on Distributed Frameworks for Multimedia Applications,2010,"At the present time, fish disease information in Indonesia is limited and just documented partially in research reports, journals, and books. Otherwise, the latest and complete information about problem of fish disease were difficult to get by fish farmers, related agencies, and research groups. The limited dissemination of information on fish diseases had caused difficulties to controlling fish diseases in Indonesia. Therefore, it was needed to develop the computer programs or software to identify and controlling fish diseases in Indonesia. Software design method was using Based Reasoning Case (CBR). CBR scheme includes retrieve, reuse, revise, and retain. The retrieve stage of the cases used the nearest neighbor technique. This system has been built conceptually as basis for further programming development. By these methods, a variety of fish disease cases will be processed by computer systems based on similar cases that occurred formerly, and will be given the appropriate solution.",1
129,A Software Cost Ontology System for Assisting Estimation of Software Project Effort for Use with Case-Based Reasoning,2006 Innovations in Information Technology,2006,"Software project cost and effort estimation has become an increasingly important field in the past years due to the overwhelming role of software in today's global market. Several studies have been dedicated to create models in order to estimate the effort of software development. Most of the studies focused on expert judgment, analogy, parametric and algorithmic methods, bottom-up methods, and top-down methods. Nearly all estimating methods need information about how projects have been implemented in the past. However, this information may be of limited use to estimators, as there are uncertainties in the way that various terms, variables and factors are being interpreted. Two projects that may seem similar may indeed be different in a critical way. Moreover, the uncertainty in assessing similarities and differences means that two different analysts could develop significantly different views and effort estimates. The major contributions this paper makes are: 1) identification of an ontology-based cost estimation process framework for defining the semantics of project development data; 2) introduce the culture factor as it affects the software effort estimation; and 3) development of a software effort estimation ontology system (SEEOS) for use in estimating software project cost in a group of organizations. The system establishes a set of common project parameters between different projects and provides a common understanding of project parameters and their semantics. This system enables project managers to elicit software project features that are semantically compatible with new project requirements. The system has been implemented using Java and a relational database management system and data which have been collected from within UAE companies using an online system",8
130,An application of structural modeling and automated reasoning to concurrent program design,[1989] Proceedings of the Twenty-Second Annual Hawaii International Conference on System Sciences. Volume II: Software Track,1989,"An application of structural modeling and automated reasoning as an intelligent software development environment for concurrent programs is presented. This application, using an integration of software reuse and theorem-proving methods, synthesizes an absolutely correct program and increases software productivity. The concurrent programs are described by a Prolog-based concurrent object-oriented language called MENDEL/87. The functional part of the reusable component is generated by structural modeling, and the synchronization part is synthesized from temporal-logic specifications by the use of an automated-reasoning mechanism. A description is also given of the MENDELS ZONE, implemented on a Prolog machine, which is the working base of the method.<>",4
131,Applying case reuse and rule-based reasoning (RBR) in object-oriented application framework documentation: Analysis and design,2008 Conference on Human System Interactions,2008,"The main objective of an object-oriented application framework is to promote the reuse of both design and code in the development of new applications. The use of a framework will significantly decrease the amount of time taken for developing new applications. However, new framework users find that the documentation provided along with a framework is usually not very effective for new users. So, in this paper, we decided to apply another form of reuse, which is information reuse, to framework documentation. In order to come up with new solutions to new problems posed by the framework users, our proposed documentation approach will reuse previously documented cases, which have solved similar framework usage problems in the past. This requires the documentation system to be capable of understanding and learning from past experiences. We believe that with the reuse of past cases for solving new problems, new framework users will be able to dramatically improve their software development performance. The use of rule-based reasoning and genetic algorithms will optimize the case search and case adaptation process.",3
132,Verification of Intelligent Agents with ACTL for Epistemic Reasoning,2006 International Conference on Computational Inteligence for Modelling Control and Automation and International Conference on Intelligent Agents Web Technologies and International Commerce (CIMCA'06),2006,"Verification of multi-agent systems (MAS) is a huge challenge, especially for those systems where security and safety are of major importance. Verification detects faults, defects and drawbacks in an early stage of software development. Here, we give a formal model for verification of MAS by means of model checking technique. We extend the existing action computation tree logic (ACTL) with epistemic operators in order to reason about knowledge properties of MAS. We introduce new operators for manipulation on agent's actions with data. We explain their syntax and semantics for our ACTL-er (ACTL for epistemic reasoning), and provide a case study for a MAS system of foraging bees.",1
133,Reasoning about Stakeholder Groups for Requirements Negotiation Based on Power Relationships,2013 20th Asia-Pacific Software Engineering Conference (APSEC),2013,"With the increasing complexity and uncertainty in requirements engineering (RE), the impact of power relationships between stakeholders becomes critical to the success of requirements engineering process, especially in requirements negotiation to resolve conflicting requirements. In this paper, we make use of the basic principles of requirements negotiation and define reasoning rules to reason about stakeholder groups for requirements negotiation, based on an extended i modeling framework that represents the power relationships between stakeholders in RE. We derive decision-makers and supporter groups of conflicting requirements using the reasoning rules based on power relationships between stakeholders, and further reason about representative stakeholders from the supporter groups to participate in requirements negotiation activity. We describe the reasoning process and provide a concrete case of reasoning about stakeholder groups for requirements negotiation based on the extended i model.",4
134,Reasoning about integration issues during requirements definition: a knowledge-based approach,Proceedings of the Second International Conference on Systems Integration,1992,"In practice, requirements engineering is not just a front-end to the system development process but a complex communication and negotiation process involving both the customers and the vendors. Further, an envisioned system is seldom defined without considering the customer's embedded base and off-the-shelf vendor solutions. A key problem in requirements engineering is to determine and track the dependencies between an envisioned system's requirements and the characteristics of related systems. Integration is an essential element of requirements definition. The authors present requirements modeling framework, i.e. a representation scheme to capture system requirements information in a knowledge base. They illustrate how the features of the framework express dependencies among system specifications and facilitate simple integration analyses during requirements definition. The framework is the basis for a requirements assistant, a software tool that enables an analyst to create, analyze and modify requirements information in a knowledge base.<>",2
135,A metamodeling approach for reasoning on multiple requirements models,2013 17th IEEE International Enterprise Distributed Object Computing Conference,2013,"The complex software development projects of today may require developers to use multiple requirements engineering approaches. Different teams may have to use different requirements modeling formalisms to express requirements related to their assigned parts of a given project. This situation poses difficulties in achieving interoperability and integration of requirements models for the purpose of reasoning on the overall system requirements. It is challenging to compose distributed models expressed in different notations and to reason on the composed models. In this paper we present a metamodeling approach which allows reasoning about requirements and their relations on the whole/composed models expressed in different requirements modeling approaches. In a previous work we expressed the structure of requirements documents as a requirements metamodel in which the most important elements are requirements relations and their types. The semantics of these elements is given in First Order Logic (FOL) and allows two activities: inferring new relations from the initial set of relations and checking consistency of relations. In this work we use the requirements metamodel as a core metamodel to be specialized for different requirements modeling approaches and notations such as Product-line and SysML. Mainly, the requirements relations in the metamodel are specialized to support relations in different requirements modeling approaches. The specialization allows using the same semantics and reasoning mechanism of the core metamodel for multiple requirements modeling approaches. To illustrate the approach we use an example from automotive domain expressed with two modeling approaches: product-line requirements models and SysML for system requirements.",6
136,A methodology for preprocessing data for application of case based reasoning,2012 XXXVIII Conferencia Latinoamericana En Informatica (CLEI),2012,"Produce quality software inside expected time and low cost has been one of the main challenges in the software industry today. Therefore, it is fundamental make estimates of size, effort, resources, cost and time spent in the software development process. Predictive models such as models based on analogy can be an alternative, especially in small and medium sized software development, they need perform reliable estimates. In this paper, we propose a methodology for pre-processing of data for use in software effort estimation. The results of use this methodology, applying Case Based Reasoning - CBR, indicate that the pre-processing enables to improve the accuracy of estimates.",2
137,An intelligent assistant for software information checking using a non-monotonic reasoning system,[1989] Proceedings of the Twenty-Second Annual Hawaii International Conference on System Sciences. Volume II: Software Track,1989,"The knowledge representation of software component relations using nonmonotonic logic to assist the validity and integrity checking of software information is presented. Software components and their interconnection information are represented by axioms that exhibit the structure and behavior of the software system. Another set of axioms represents the basic truisms about a software system in general. These axioms can easily be extended to cover a wide variety of software systems architectures. In the software development and maintenance phases, information about the software system can be derived from these axioms using an automated reasoning system, and the software system itself can easily be checked against a specification of the system and compared for validity. This knowledge-based system will provide programmers with useful software information and assist the software development and maintenance process.<>",0
138,Reasoning over the Evolution of Source Code Using Quantified Regular Path Expressions,2011 18th Working Conference on Reverse Engineering,2011,"Version control systems (VCS) have become indispensable to develop software. Next to their immediate advantages, they also offer information about the evolution of software and its development process. Despite this wealth of information, it has only been leveraged by tools that are dedicated to a specific software engineering task such as predicting bugs or identifying hotspots. General-purpose tool support for reasoning about the information contained in a version control system is limited. In this paper, we introduce the logic-based program query language ABSINTHE. It supports querying versioned software systems using logic queries in which quantified regular path expressions are embedded. These expressions lend themselves to specifying the properties that each individual version in a sequence of successive software versions ought to exhibit.",5
139,"Agents, Case-Based Reasoning and their relation to the Mexican Software Process Model (MoProSoft)",31st Annual International Computer Software and Applications Conference (COMPSAC 2007),2007,"The MoProSoft Integral Tool, or HIM for its name in Spanish, is a Web-designed system to support monitoring the MoProSoft, a software process model defined as part of a strategy to encourage the software industry in Mexico. The HIM-assistant, is a system added to the HIM, which main objectives are to give a guide for the automated use of the MoProSoft and improve the aid provided to the HIM users. To reach these objectives, elements from software engineering along with two areas of artificial intelligence, multi- agent systems and case based reasoning, were applied to develop the HIM-assistant. The task involved the HIM-assistant analysis and design phases using the MESSAGE methodology, as well as the development of the system and the performance of tests. The major importance of the work lies on the integration of different areas to fulfill the objectives, using existing progress instead of developing a totally new solution.",3
140,Reasoning about semantic Web in Isabelle/HOL,11th Asia-Pacific Software Engineering Conference,2004,"Semantic Web is regarded as the next generation of the World Wide Web. It provides not only the structure of the Web but also meaningful semantics for the information presented. To make semantic Web services understandable for distributed agents, formal definitions of the ontologies and their consistencies are essential. However, the existing tools for reasoning about semantic Web ontologies are still primitive. We believe that mature software engineering tools, such as theorem provers, can contribute to the reasoning phase. In this paper, we present an approach of encoding the semantic Web ontology (DAML+OIL) into the generic theorem prover Isabelle/HOL for automatic reasoning. Furthermore, a translation tool was developed to transform semantic Web ontologies into their extended Isabelle theories. With additional intermediate lemmas, Isabelle can be used to perform both subsumption (class) level and instantiation (instance) level reasoning of the semantic Web ontologies.",1
141,What is default reasoning good for? Applications revisited,Proceedings of the 32nd Annual Hawaii International Conference on Systems Sciences. 1999. HICSS-32. Abstracts and CD-ROM of Full Papers,1999,"Default reasoning comprises methods of reasoning with uncertain and incomplete information which share the idea of using default rules to represent plausible conclusions. Even though the applicational scope of default reasoning was clear right from the beginning, research focussed heavily on theoretical aspects and neglected for a long time pragmatic and applicational questions. This, coupled with a presentation that is usually too technical for potential applicants of this technology has led to the impression that default reasoning (and other forms of nonmonotonic reasoning) have very little relevance to practice. This paper seeks to counter this view. It describes the basic advantages of using defaults in the representation of information and in reasoning with information. And then it presents applications of default reasoning in various areas, such as software engineering, information retrieval, law, graphics design etc.",1
142,Engineering design support through case-based reasoning,IEE Colloquium on Intelligent Design Systems (Digest No. 1997/016),1997,"The potential application of case based reasoning (CBR) in design support is illustrated by means of three examples drawn from past and current research at the University of Paisley. The examples demonstrate the suitability of CBR in different aspects of design, different problem areas, and to meet different design goals. The examples are: a quality advisory system for the designer in the early stages of mechanical engineering design; the integration of case based reasoning with aspects of quality function deployment as a means of identifying suitable metrics in software engineering design; a domain and tool independent environment to support the traceability and documentation of the work of either a single designer or a design team in conceptual design.",1
143,A Case-Based Reasoning Method for Processing Model Recognition and Reuse in Program Comprehension,2006 International Conference on Computational Intelligence and Security,2006,"Applying cased-based reasoning (CBR) method in program understanding provides a practical route towards more powerful software engineering technology. A CBR approach to the recognition of model component is presented, and the whole reasoning process of the recognition is presented, including a case representation method and a matching algorithm. A prototype system named process model component recognition & reuse (PMCRR) is developed to implement model transformation and reconstruction. At last, an example is illustrated to check the efficiency of CBR method",0
144,Object-oriented model-based reasoning for diagnosing automated manufacturing systems,Proceedings IEEE International Symposium on Intelligent Control 1988,1988,"In automated manufacturing, availability is the percentage of time that a production system is functioning properly. The author addresses the problems of availability by exploring the feasibility of a class of diagnosis algorithm. To develop this approach, a range of theory used in other areas was surveyed and synthesized. Petri net analysis was applied to fault detection. Rule-based inference and model-based reasoning were applied to failure isolation and hypothesis validation. A large part of the effort was the use of object-oriented software engineering to integrate the pieces into a unified algorithm. A software system was developed to realize the advanced algorithm and applied to a case study manufacturing subsystem for evaluation and analysis.<>",0
145,Visually Reasoning about System and Resource Behavior,2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C),2016,"Understanding how software utilizes resources is an important software engineering task. Existing software comprehension approaches rarely consider how resource utilization affects system behavior. We present Perfume, a general-purpose tool to help developers understand how resource utilization impacts their systems' control flow. Perfume is broadly applicable, as it is configurable to parse a wide variety of execution log formats and applies to all resource types that can be represented numerically. Perfume mines temporal properties that hold over the logged executions and represents system behavior in a resource finite state automaton that satisfies the mined properties. Perfume's interactive interface allows the developers to understand system behavior and to formulate and test hypotheses about system executions. A controlled experiment with 40 students shows that Perfume effectively supports understanding and debugging tasks. Students using Perfume answered 8.3% more questions correctly than those using execution logs alone and did so 15.5% more quickly. Perfume is open source and deployed at http://perfume.cs.umass.edu/.",0
146,Reasoning about Human Intention Change for Individualized Runtime Software Service Evolution,2010 IEEE 34th Annual Computer Software and Applications Conference,2010,"While software evolution has been studied extensively in software engineering, few of these efforts have involved a systematic exploration of human epistemological attitudes, such as human desire and intention, as the driving force of software service evolution. Our work proposes a theoretical framework to monitor and reason about human intention and its changes, which in turn can be used to determine how software and services should evolve to be individualized and better serve each user. Extending the Situ framework, we explore the service satisfiability problem through sub-world coverage following Kripke semantics, which enjoys wide application in AI and other fields related to human epistemic reasoning.",7
147,Reasoning About Identifier Spaces: How to Make Chord Correct,IEEE Transactions on Software Engineering,2017,"The Chord distributed hash table (DHT) is well-known and often used to implement peer-to-peer systems. Chord peers find other peers, and access their data, through a ring-shaped pointer structure in a large identifier space. Despite claims of proven correctness, i.e., eventual reachability, previous work has shown that the Chord ring-maintenance protocol is not correct under its original operating assumptions. Previous work has not, however, discovered whether Chord could be made correct under the same assumptions. The contribution of this paper is to provide the first specification of correct operations and initialization for Chord, an inductive invariant that is necessary and sufficient to support a proof of correctness, and two independent proofs of correctness. One proof is informal and intuitive, and applies to networks of any size. The other proof is based on a formal model in Alloy, and uses fully automated analysis to prove the assertions for networks of bounded size. The two proofs complement each other in several important ways.",22
148,Transparent decision support using statistical reasoning and fuzzy inference,IEEE Transactions on Knowledge and Data Engineering,2006,"A framework for the development of a decision support system (DSS) that exhibits uncommonly transparent rule-based inference logic is introduced. A DSS is constructed by marrying a statistically based fuzzy inference system (FIS) with a user interface, allowing drill-down exploration of the underlying statistical support, providing transparent access to both the rule-based inference as well as the underlying statistical basis for the rules. The FIS is constructed through a ""pattern discovery"" based analysis of training data. Such an analysis yields a rule base characterized by simple explanations for any rule or data division in the extracted knowledge base. The reliability of a fuzzy inference is well predicted by a confidence measure that determines the probability of a correct suggestion by examination of values produced within the inference calculation. The combination of these components provides a means of constructing decision support systems that exhibit a degree of transparency beyond that commonly observed in supervised-learning-based methods. A prototype DSS is analyzed in terms of its workflow and usability, outlining the insight derived through use of the framework. This is demonstrated by considering a simple synthetic data example and a more interesting real-world example application with the goal of characterizing patients with respect to risk of heart disease. Specific input data samples and corresponding output suggestions created by the system are presented and discussed. The means by which the suggestions made by the system may be used in a larger decision context is evaluated",12
149,Learning Project Management Decisions: A Case Study with Case-Based Reasoning versus Data Farming,IEEE Transactions on Software Engineering,2013,"Background: Given information on just a few prior projects, how do we learn the best and fewest changes for current projects? Aim: To conduct a case study comparing two ways to recommend project changes. 1) Data farmers use Monte Carlo sampling to survey and summarize the space of possible outcomes. 2) Case-based reasoners (CBR) explore the neighborhood around test instances. Method: We applied a state-of-the data farmer (SEESAW) and a CBR tool ()'V2) to software project data. Results: CBR with )'V2 was more effective than SEESAW's data farming for learning best and recommended project changes, effectively reducing runtime, effort, and defects. Further, CBR with )'V2 was comparably easier to build, maintain, and apply in novel domains, especially on noisy data sets. Conclusion: Use CBR tools like )'V2 when data are scarce or noisy or when project data cannot be expressed in the required form of a data farmer. Future Work: This study applied our own CBR tool to several small data sets. Future work could apply other CBR tools and data farmers to other data (perhaps to explore other goals such as, say, minimizing maintenance effort).",9
150,DATESSO: Self-Adapting Service Composition with Debt-Aware Two Levels Constraint Reasoning,2020 IEEE/ACM 15th International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS),2020,"The rapidly changing workload of service-based systems can easily cause under-/over-utilization on the component services, which can consequently affect the overall Quality of Service (QoS), such as latency. Self-adaptive services composition rectifies this problem, but poses several challenges: (i) the effectiveness of adaptation can deteriorate due to over-optimistic assumptions on the latency and utilization constraints, at both local and global levels; and (ii) the benefits brought by each composition plan is often short term and is not often designed for long-term benefits—a natural prerequisite for sustaining the system. To tackle these issues, we propose a two levels constraint reasoning framework for sustainable self-adaptive services composition, called DATESSO. In particular, DATESSO consists of a refined formulation that differentiates the ‘strictness’ for latency/utilization constraints in two levels. To strive for long-term benefits, DATESSO leverages the concept of technical debt and time-series prediction to model the utility contribution of the component services in the composition. The approach embeds a debt-aware two level constraint reasoning algorithm in DATESSO to improve the efficiency, effectiveness and sustainability of self-adaptive service composition. We evaluate DATESSO on a service-based system with real-world WS-DREAM dataset and comparing it with other state-of-the-art approaches. The results demonstrate the superiority of DATESSO over the others on the utilization, latency and running time whilst likely to be more sustainable.",1